{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de se code est de scrapper les prix littéraires en France entre 2019 et 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on importe la bibliothèque requests\n",
    "import requests\n",
    "from bs4 import BeautifulSoup # on importe BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée un dataframe vide avec comme colonnes les infos qu'on va importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Année, Prix, Auteur, Titre]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "colonnes = ['Année', 'Prix', 'Auteur', 'Titre']\n",
    "\n",
    "# Créer un DataFrame vide avec ces colonnes\n",
    "df = pd.DataFrame(columns=colonnes)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wikipedia_page_france(year):\n",
    "    global df\n",
    "    url = f\"https://fr.wikipedia.org/wiki/Prix_litt%C3%A9raires_{year}\"\n",
    "    response = requests.get(url)\n",
    "    response.encoding = \"utf-8\"  # On garantit le bon encodage\n",
    "\n",
    "    if response.status_code == 200:  # On vérifie si la requête est un succès\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # On recherche la section France\n",
    "        france_section = soup.find('h2', string=\"France\")\n",
    "        if france_section:\n",
    "            # La liste <ul> qui suit contient les prix pour la France\n",
    "            france_list = france_section.find_next('ul')\n",
    "\n",
    "            if france_list:\n",
    "                # On recherche tous les <li> dans la liste\n",
    "                prizes = france_list.find_all('li')\n",
    "\n",
    "                # On extrait les données\n",
    "                for prize in prizes:\n",
    "                    # Nom du prix\n",
    "                    prize_name = prize.find('a')\n",
    "                    prize_name = prize_name.text.strip() if prize_name else None\n",
    "\n",
    "                    # Auteur\n",
    "                    author = prize.find_all('a')\n",
    "                    author = author[1].text.strip() if len(author) > 1 else None\n",
    "\n",
    "                    # Titre\n",
    "                    title = prize.find('i')\n",
    "                    title = title.text.strip() if title else None\n",
    "\n",
    "                    # On ajoute les résultats si les données sont complètes\n",
    "                    if prize_name and author and title:\n",
    "                        new_row = {'Année': year, 'Prix': prize_name, 'Auteur': author, 'Titre': title}\n",
    "                        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Section 'France' non trouvée pour l'année {year}\")\n",
    "    else:\n",
    "        print(f\"Erreur lors du scraping de l'année {year}: Status code {response.status_code}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2019, 2024):\n",
    "    scrape_wikipedia_page_france(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Année</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina</td>\n",
       "      <td>Par les routes</td>\n",
       "      <td>Par les routes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina étranger</td>\n",
       "      <td>Ordesa</td>\n",
       "      <td>Ordesa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina essai</td>\n",
       "      <td>Emmanuelle Lambert</td>\n",
       "      <td>Giono furioso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina des lycéens</td>\n",
       "      <td>La Chaleur</td>\n",
       "      <td>La Chaleur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Goncourt</td>\n",
       "      <td>Tous les hommes n'habitent pas le monde de la ...</td>\n",
       "      <td>Tous les hommes n'habitent pas le monde de la ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Année                     Prix  \\\n",
       "0  2019              Prix Femina   \n",
       "1  2019     Prix Femina étranger   \n",
       "2  2019        Prix Femina essai   \n",
       "3  2019  Prix Femina des lycéens   \n",
       "4  2019            Prix Goncourt   \n",
       "\n",
       "                                              Auteur  \\\n",
       "0                                     Par les routes   \n",
       "1                                             Ordesa   \n",
       "2                                 Emmanuelle Lambert   \n",
       "3                                         La Chaleur   \n",
       "4  Tous les hommes n'habitent pas le monde de la ...   \n",
       "\n",
       "                                               Titre  \n",
       "0                                     Par les routes  \n",
       "1                                             Ordesa  \n",
       "2                                      Giono furioso  \n",
       "3                                         La Chaleur  \n",
       "4  Tous les hommes n'habitent pas le monde de la ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un fichier CSV afin de vérifier s'il n'y a pas d'incohérences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"prix_litteraires.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARTIE: Corriger les incohérences de la table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "# Fonction pour rechercher un livre sur Babelio et accéder à la page du premier résultat\n",
    "def search_wikipedia(book_title, year):\n",
    "    #reformulation du titre en différente partie\n",
    "    parts = re.findall(r'\\w+|[^\\w\\s]', book_title)\n",
    "\n",
    "    # URL de recherche sur Livraddict\n",
    "    search_title = '%20'.join(parts)\n",
    "    lower_search_title = '%20'.join(parts).lower()\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    search_url = f'https://www.bing.com/search?q=Livre%20{search_title}%20{year}%20wikipedia&qs=n&form=QBRE&sp=-1&ghc=1&lq=0&pq=livre%20{lower_search_title}%20{year}%20wikipedia&sc=11-30&sk=&cvid=88409FB04E76408A93DE43207AD5027F&ghsh=0&ghacc=0&ghpl='\n",
    "\n",
    "    # Faire une requête pour récupérer la page des résultats de recherche\n",
    "    response = requests.get(search_url, headers=headers).content\n",
    "    response_text = response.decode('utf-8')\n",
    "    # Trouver le premier élément correspondant au lien d'un résultat\n",
    "    page = BeautifulSoup(response_text, \"html.parser\")\n",
    "    first_result = page.find('li', class_='b_algo')  # Trouve le premier résultat\n",
    "    if first_result:\n",
    "        link = first_result.find('a', href=True)  # Trouve le lien à l'intérieur de <a>\n",
    "        if link:\n",
    "            href = link['href']\n",
    "            # Si c'est une URL relative, complète-la\n",
    "            if href.startswith('/wiki'):\n",
    "                href = 'https://fr.wikipedia.org' + href\n",
    "            return href\n",
    "        else:\n",
    "                print(\"Pas de lien trouvé dans le premier résultat.\")\n",
    "                return None\n",
    "    else:\n",
    "            print(\"Pas de résultats trouvés.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(book_title, year):\n",
    "    #reformulation du titre en différente partie\n",
    "    parts = re.findall(r'\\w+|[^\\w\\s]', book_title)\n",
    "\n",
    "    # URL de recherche sur Livraddict\n",
    "    search_title = '%20'.join(parts)\n",
    "    lower_search_title = '%20'.join(parts).lower()\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    search_url = f'https://www.bing.com/search?q=Livre%20{search_title}%20{year}&qs=n&form=QBRE&sp=-1&ghc=1&lq=0&pq=livre%20{lower_search_title}%20{year}&sc=11-30&sk=&cvid=88409FB04E76408A93DE43207AD5027F&ghsh=0&ghacc=0&ghpl='\n",
    "\n",
    "    # Faire une requête pour récupérer la page des résultats de recherche\n",
    "    response = requests.get(search_url, headers=headers).content\n",
    "    response_text = response.decode('utf-8')\n",
    "    # Trouver le premier élément correspondant au lien d'un résultat\n",
    "    page = BeautifulSoup(response_text, \"html.parser\")\n",
    "    sponsored_results = page.find_all('li', class_='b_ad')\n",
    "    \n",
    "    # Parcourir les 15 premiers résultats (ou jusqu'à trouver un lien Wikipedia)\n",
    "    for result in sponsored_results[:15]:  # Limiter à 15 résultats\n",
    "        link = result.find('a', href=True)\n",
    "        if link and \"wikipedia.org\" in link['href']:  # Vérifie si c'est un lien vers Wikipedia\n",
    "            return link['href']\n",
    "    \n",
    "        else:\n",
    "            print(\"Aucun lien Wikipedia trouvé.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour récupérer l'information sur l'auteur depuis la page wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recup_info(url):\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    response = requests.get(url, headers=headers).text\n",
    "    if response == None:\n",
    "        author = \"problème d'URL\"\n",
    "    page = BeautifulSoup(response, \"html.parser\")\n",
    "    table = page.find('table', {'class': 'infobox'})\n",
    "    if table == None:\n",
    "        author = \"Erreur de trouvaille de la table wikipédia\" \n",
    "    else: \n",
    "        rows = table.find_all('tr')\n",
    "        if rows == None:\n",
    "            author = \"Pas de catégories trouvées dans la table\"\n",
    "        else:\n",
    "            tr_author = rows.find(\"tr\")\n",
    "            if tr_author == None:\n",
    "                author = \"Pas de rubrique auteur dans la table\"\n",
    "            else:\n",
    "                td_author = tr_author.find(\"td\")\n",
    "                if td_author == None:\n",
    "                    author = \"Pas de nom dans la ligne auteur (td)\"\n",
    "                else:\n",
    "                    a_autor = td_author.find(\"a\")\n",
    "                    if a_autor == None :\n",
    "                        author = \"Pas de nom dans la ligne auteur (a)\"\n",
    "                    else:\n",
    "                        author = a_autor.get(\"title\")\n",
    "                        if author == None:\n",
    "                            author = \"Pas de nom dans la ligne auteur (title)\"\n",
    "        \n",
    "    return author\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_author(row):\n",
    "    if row[\"Auteur\"] == row[\"Titre\"]:\n",
    "        url = search_wikipedia(\"Titre\", \"Année\")\n",
    "        author = recup_info(url)\n",
    "        return author\n",
    "    else:\n",
    "        return row[\"Auteur\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction globale allant chercher l'auteur de l'ouvrage quand ce dernier n'est pas indiqué"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type_de_document'] = df.apply(search_author, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Année</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>Titre</th>\n",
       "      <th>type_de_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina</td>\n",
       "      <td>Par les routes</td>\n",
       "      <td>Par les routes</td>\n",
       "      <td>Erreur de trouvaille de la table wikipédia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina étranger</td>\n",
       "      <td>Ordesa</td>\n",
       "      <td>Ordesa</td>\n",
       "      <td>Erreur de trouvaille de la table wikipédia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina essai</td>\n",
       "      <td>Emmanuelle Lambert</td>\n",
       "      <td>Giono furioso</td>\n",
       "      <td>Emmanuelle Lambert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina des lycéens</td>\n",
       "      <td>La Chaleur</td>\n",
       "      <td>La Chaleur</td>\n",
       "      <td>Erreur de trouvaille de la table wikipédia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Goncourt</td>\n",
       "      <td>Tous les hommes n'habitent pas le monde de la ...</td>\n",
       "      <td>Tous les hommes n'habitent pas le monde de la ...</td>\n",
       "      <td>Erreur de trouvaille de la table wikipédia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Année                     Prix  \\\n",
       "0  2019              Prix Femina   \n",
       "1  2019     Prix Femina étranger   \n",
       "2  2019        Prix Femina essai   \n",
       "3  2019  Prix Femina des lycéens   \n",
       "4  2019            Prix Goncourt   \n",
       "\n",
       "                                              Auteur  \\\n",
       "0                                     Par les routes   \n",
       "1                                             Ordesa   \n",
       "2                                 Emmanuelle Lambert   \n",
       "3                                         La Chaleur   \n",
       "4  Tous les hommes n'habitent pas le monde de la ...   \n",
       "\n",
       "                                               Titre  \\\n",
       "0                                     Par les routes   \n",
       "1                                             Ordesa   \n",
       "2                                      Giono furioso   \n",
       "3                                         La Chaleur   \n",
       "4  Tous les hommes n'habitent pas le monde de la ...   \n",
       "\n",
       "                             type_de_document  \n",
       "0  Erreur de trouvaille de la table wikipédia  \n",
       "1  Erreur de trouvaille de la table wikipédia  \n",
       "2                          Emmanuelle Lambert  \n",
       "3  Erreur de trouvaille de la table wikipédia  \n",
       "4  Erreur de trouvaille de la table wikipédia  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METHODE 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_answer_from_bing(question):\n",
    "    # Reformulation de la question pour l'URL\n",
    "    question_query = '+'.join(question.split())\n",
    "\n",
    "    # URL de recherche Bing pour poser la question\n",
    "    search_url = f\"https://www.bing.com/search?q={question_query}\"\n",
    "\n",
    "    # En-têtes pour simuler une requête depuis un navigateur\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    # Faire une requête pour récupérer la page des résultats de recherche\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    response_text = response.content.decode('utf-8')\n",
    "\n",
    "    # Analyser la page HTML avec BeautifulSoup\n",
    "    page = BeautifulSoup(response_text, \"html.parser\")\n",
    "\n",
    "    # Recherche de la réponse directe dans les résultats\n",
    "    snippet = page.find('div', {'class': 'b_ans'})  # Le snippet direct, souvent la première réponse\n",
    "\n",
    "    # Si pas trouvé dans b_ans, on peut chercher dans un autre endroit comme la description du premier résultat\n",
    "    if not snippet:\n",
    "        # Recherche de la première description (parfois utilisée pour les réponses courtes)\n",
    "        first_result_desc = page.find('li', {'class': 'b_algo'})\n",
    "        if first_result_desc:\n",
    "            snippet = first_result_desc.find('p')\n",
    "    \n",
    "    # Si un extrait de texte a été trouvé\n",
    "    if snippet:\n",
    "        answer = snippet.get_text(strip=True)\n",
    "        return answer\n",
    "    else:\n",
    "        return \"Aucune réponse directe trouvée.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATTENTION, il faut entrer ce code dans le terminal: python -m spacy download fr_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author(answer):\n",
    "    import spacy\n",
    "    if answer == \"Aucune réponse directe trouvée.\":\n",
    "        author = \"Auteur non trouvé\"\n",
    "    else:\n",
    "        # Charger le modèle français pré-entraîné\n",
    "        nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "        # Phrase d'exemple\n",
    "        text = \"Par les routes est un roman de Sylvain Prudhomme paru le 22 août 2019 aux éditions Gallimard – L'Arbalète et ayant reçu la même année le prix Femina.\"\n",
    "\n",
    "        # Traiter le texte avec le modèle spaCy\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Extraire les entités nommées (NER)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'PER':\n",
    "                author = ent.text\n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_question(title, year):\n",
    "    question = \"qui a écrit\"+ title + \"en\" +year\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_author(row):\n",
    "    if row[\"Auteur\"] == row[\"Titre\"]:\n",
    "        question = gen_question(row[\"Titre\"], row[\"Année\"])\n",
    "        answer = get_answer_from_bing(question)\n",
    "        author = get_author(answer)\n",
    "    else:\n",
    "        author = row[\"Auteur\"]\n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuteur\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_author\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m, in \u001b[0;36msearch_author\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_author\u001b[39m(row):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuteur\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitre\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m         question \u001b[38;5;241m=\u001b[39m \u001b[43mgen_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTitre\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnnée\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         answer \u001b[38;5;241m=\u001b[39m get_answer_from_bing(question)\n\u001b[1;32m      5\u001b[0m         author \u001b[38;5;241m=\u001b[39m get_author(answer)\n",
      "Cell \u001b[0;32mIn[58], line 2\u001b[0m, in \u001b[0;36mgen_question\u001b[0;34m(title, year)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen_question\u001b[39m(title, year):\n\u001b[0;32m----> 2\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqui a écrit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m question\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "df['Auteur'] = df.apply(search_author, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://livrecritique.com/par-les-routes-2019-resume-du-roman-de-sylvain-prudhomme/'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia(\"Par les routes\", \"2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr>\n",
       " <td class=\"entete universite italique\" colspan=\"2\" style=\"background-color:#7DA7D9;color:black;\">La Mer des monstres<style data-mw-deduplicate=\"TemplateStyles:r160407116\">.mw-parser-output .entete.universite{background-image:url(\"//upload.wikimedia.org/wikipedia/commons/4/42/Picto_infobox_book.png\")}</style>\n",
       " </td></tr>,\n",
       " <tr><td colspan=\"2\" style=\"display:none;\">\n",
       " </td></tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Auteur\n",
       " </th>\n",
       " <td><a href=\"/wiki/Rick_Riordan\" title=\"Rick Riordan\">Rick Riordan</a>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Pays\n",
       " </th>\n",
       " <td><span class=\"nowrap\"><span class=\"datasortkey\" data-sort-value=\"États unis\"><span class=\"flagicon\"><span class=\"mw-image-border noviewer\" typeof=\"mw:File\"><a class=\"mw-file-description\" href=\"/wiki/Fichier:Flag_of_the_United_States.svg\" title=\"Drapeau des États-Unis\"><img alt=\"Drapeau des États-Unis\" class=\"mw-file-element\" data-file-height=\"650\" data-file-width=\"1235\" decoding=\"async\" height=\"11\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Flag_of_the_United_States.svg/20px-Flag_of_the_United_States.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Flag_of_the_United_States.svg/30px-Flag_of_the_United_States.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Flag_of_the_United_States.svg/40px-Flag_of_the_United_States.svg.png 2x\" width=\"20\"/></a></span> </span><a href=\"/wiki/%C3%89tats-Unis\" title=\"États-Unis\">États-Unis</a></span></span>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Genre\n",
       " </th>\n",
       " <td><a href=\"/wiki/Roman_(litt%C3%A9rature)\" title=\"Roman (littérature)\">Roman</a><br/><a href=\"/wiki/Fantasy\" title=\"Fantasy\">Fantasy</a>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th colspan=\"2\" style=\"padding:4px; text-align:center; background-color:#7DA7D9; color:#000000\">Version originale</th></tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Langue\n",
       " </th>\n",
       " <td><a href=\"/wiki/Anglais_am%C3%A9ricain\" title=\"Anglais américain\">Anglais américain</a>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Titre\n",
       " </th>\n",
       " <td><i>The Sea of Monsters</i>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Éditeur\n",
       " </th>\n",
       " <td><a href=\"/wiki/Miramax_Books\" title=\"Miramax Books\">Miramax Books</a>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Lieu de parution\n",
       " </th>\n",
       " <td><a href=\"/wiki/New_York\" title=\"New York\">New York</a>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Date de parution\n",
       " </th>\n",
       " <td><time class=\"nowrap date-lien\" data-sort-value=\"2006-03-21\" datetime=\"2006-03-21\"><a href=\"/wiki/21_mars\" title=\"21 mars\">21</a> <a href=\"/wiki/Mars_2006\" title=\"Mars 2006\">mars</a> <a href=\"/wiki/2006_en_litt%C3%A9rature\" title=\"2006 en littérature\">2006</a></time>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\"><a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>\n",
       " </th>\n",
       " <td><a href=\"/wiki/Sp%C3%A9cial:Ouvrages_de_r%C3%A9f%C3%A9rence/978-0786856862\" title=\"Spécial:Ouvrages de référence/978-0786856862\"><span class=\"nowrap\">978-0786856862</span></a>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th colspan=\"2\" style=\"padding:4px; text-align:center; background-color:#7DA7D9; color:#000000\">Version française</th></tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Traducteur\n",
       " </th>\n",
       " <td>Mona de Pracontal\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Éditeur\n",
       " </th>\n",
       " <td><a href=\"/wiki/%C3%89ditions_Albin_Michel\" title=\"Éditions Albin Michel\">Albin Michel</a>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Collection\n",
       " </th>\n",
       " <td><a href=\"/wiki/Wiz_(collection)\" title=\"Wiz (collection)\">Wiz</a>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Lieu de parution\n",
       " </th>\n",
       " <td><a href=\"/wiki/Paris\" title=\"Paris\">Paris</a>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Date de parution\n",
       " </th>\n",
       " <td><time class=\"nowrap date-lien\" data-sort-value=\"2007-05-22\" datetime=\"2007-05-22\"><a href=\"/wiki/22_mai\" title=\"22 mai\">22</a> <a href=\"/wiki/Mai_2007\" title=\"Mai 2007\">mai</a> <a href=\"/wiki/2007_en_litt%C3%A9rature\" title=\"2007 en littérature\">2007</a></time>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Type de média\n",
       " </th>\n",
       " <td>Livre papier\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Nombre de pages\n",
       " </th>\n",
       " <td>314\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th scope=\"row\"><a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a>\n",
       " </th>\n",
       " <td><a href=\"/wiki/Sp%C3%A9cial:Ouvrages_de_r%C3%A9f%C3%A9rence/978-2226177612\" title=\"Spécial:Ouvrages de référence/978-2226177612\"><span class=\"nowrap\">978-2226177612</span></a>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th colspan=\"2\" style=\"padding:4px; text-align:center; background-color:#7DA7D9; color:#000000\">Chronologie</th></tr>,\n",
       " <tr>\n",
       " <th scope=\"row\">Série\n",
       " </th>\n",
       " <td><i><a href=\"/wiki/Percy_Jackson\" title=\"Percy Jackson\">Percy Jackson</a></i>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <td colspan=\"2\" style=\"text-align:center;\">\n",
       " <table class=\"navigation-not-searchable\" style=\"width:100%; border-spacing:0; background-color:transparent; color:inherit;\">\n",
       " <tbody><tr>\n",
       " <td style=\"text-align:left; vertical-align:middle; width:5%; background-color:; color:inherit;\"><span typeof=\"mw:File\"><span><img alt=\"Précédent\" class=\"mw-file-element\" data-file-height=\"133\" data-file-width=\"110\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Arrleft.svg/13px-Arrleft.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Arrleft.svg/20px-Arrleft.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Arrleft.svg/26px-Arrleft.svg.png 2x\" width=\"13\"/></span></span>\n",
       " </td>\n",
       " <td style=\"width:1%; background-color:; color:inherit;\">\n",
       " </td>\n",
       " <td style=\"text-align:left; vertical-align:middle; width:44%; background-color:; color:inherit;\"> <i><a href=\"/wiki/Le_Voleur_de_foudre\" title=\"Le Voleur de foudre\">Le Voleur de foudre</a></i>\n",
       " </td>\n",
       " <td style=\"width:1%; background-color:transparent; color:inherit;\">\n",
       " </td>\n",
       " <td style=\"text-align:right; vertical-align:middle; width:44%; background-color:; color:inherit;\"> <i><a href=\"/wiki/Le_Sort_du_titan\" title=\"Le Sort du titan\">Le Sort du titan</a></i>\n",
       " </td>\n",
       " <td style=\"width:1%; background-color:; color:inherit;\">\n",
       " </td>\n",
       " <td style=\"text-align:right; vertical-align:middle; width:5%; background-color:; color:inherit;\"><span typeof=\"mw:File\"><span><img alt=\"Suivant\" class=\"mw-file-element\" data-file-height=\"133\" data-file-width=\"110\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Arrright.svg/13px-Arrright.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Arrright.svg/20px-Arrright.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Arrright.svg/26px-Arrright.svg.png 2x\" width=\"13\"/></span></span>\n",
       " </td>\n",
       " </tr>\n",
       " </tbody></table>\n",
       " </td></tr>,\n",
       " <tr>\n",
       " <td style=\"text-align:left; vertical-align:middle; width:5%; background-color:; color:inherit;\"><span typeof=\"mw:File\"><span><img alt=\"Précédent\" class=\"mw-file-element\" data-file-height=\"133\" data-file-width=\"110\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Arrleft.svg/13px-Arrleft.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Arrleft.svg/20px-Arrleft.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Arrleft.svg/26px-Arrleft.svg.png 2x\" width=\"13\"/></span></span>\n",
       " </td>\n",
       " <td style=\"width:1%; background-color:; color:inherit;\">\n",
       " </td>\n",
       " <td style=\"text-align:left; vertical-align:middle; width:44%; background-color:; color:inherit;\"> <i><a href=\"/wiki/Le_Voleur_de_foudre\" title=\"Le Voleur de foudre\">Le Voleur de foudre</a></i>\n",
       " </td>\n",
       " <td style=\"width:1%; background-color:transparent; color:inherit;\">\n",
       " </td>\n",
       " <td style=\"text-align:right; vertical-align:middle; width:44%; background-color:; color:inherit;\"> <i><a href=\"/wiki/Le_Sort_du_titan\" title=\"Le Sort du titan\">Le Sort du titan</a></i>\n",
       " </td>\n",
       " <td style=\"width:1%; background-color:; color:inherit;\">\n",
       " </td>\n",
       " <td style=\"text-align:right; vertical-align:middle; width:5%; background-color:; color:inherit;\"><span typeof=\"mw:File\"><span><img alt=\"Suivant\" class=\"mw-file-element\" data-file-height=\"133\" data-file-width=\"110\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Arrright.svg/13px-Arrright.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Arrright.svg/20px-Arrright.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Arrright.svg/26px-Arrright.svg.png 2x\" width=\"13\"/></span></span>\n",
       " </td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <td class=\"navigation-only\" colspan=\"2\" style=\"border-top: 2px #7DA7D9 solid; font-size: 80%; background:inherit; color: inherit; text-align: right;\"><span class=\"plainlinks\" style=\"float:left;\"><a class=\"external text\" href=\"https://fr.wikipedia.org/w/index.php?title=La_Mer_des_monstres&amp;action=edit&amp;section=0\"><span class=\"infodoc\">modifier</span></a></span> <span typeof=\"mw:File\"><a href=\"/wiki/Mod%C3%A8le:Infobox_Livre\" title=\"Consultez la documentation du modèle\"><img alt=\"\" class=\"mw-file-element\" data-file-height=\"512\" data-file-width=\"512\" decoding=\"async\" height=\"12\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/3/38/Info_Simple.svg/12px-Info_Simple.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/3/38/Info_Simple.svg/18px-Info_Simple.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/38/Info_Simple.svg/24px-Info_Simple.svg.png 2x\" width=\"12\"/></a></span></td>\n",
       " </tr>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recup_info('https://fr.wikipedia.org/wiki/La_Mer_des_monstres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recup_info(url):\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    response = requests.get(url, headers=headers).content\n",
    "    page = BeautifulSoup(response, \"html.parser\")\n",
    "    table = page.find('table', {'class': 'infobox'})\n",
    "    rows = table.find_all('tr')\n",
    "    return rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
