{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENCORE A FAIRE: mettre les imports tout en haut !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première étape de notre travail a été de récupérer les diverses données dont nous avions besoin afin d'essayer d'estimer l'impact des influenceurs de Youtube mais aussi des prix sur les livres les plus lus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARTIE 1: Récupérer des données sur les livres les plus lus, de différente manière"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération de l'API des bibliothèques de Paris afin d'estimer les cent livres les plus empruntés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, formulons notre requête à l'API. On met comme limite 100 ouvrages car il s'agit de la limite de collecte possible au sein de l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type de contenu : application/json; charset=utf-8\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"https://opendata.paris.fr/api/explore/v2.1/catalog/datasets/les-1000-titres-les-plus-reserves-dans-les-bibliotheques-de-pret/records?limit=100\")\n",
    "\n",
    "# Afficher le type de contenu et le texte brut de la réponse\n",
    "print(\"Type de contenu :\", response.headers.get(\"Content-Type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois l'API récupérée, on observe la structure du jeu de données pour savoir comment s'appelle la variable 'résultat' ( ici 'results') à appeler afin de créer notre dataframe panda.\n",
    "On observe que tous les rangs ne sont pas dans la base. Notre hypothèse optimiste est qu'il y a peut-être des types d'ouvrage non classés dans cette base ( et ne nous intéressant pas puisque nous nous intéressons seulement aux livres, dont la catégorie existe dans la base). C'est une hypothèse qui nous semble probable étant donné que nous avons par la suite créé nous-même des trous dans le classement en enlevant les DVDs de ce dernier. Cependant, nous ne pouvons pas en être sûrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure du JSON :\n",
      "{'total_count': 1000, 'results': [{'rang': 12, 'type_de_document': 'Livre adulte', 'reservations': 522.0, 'titre': \"Réinventer l'amour : comment le patriarcat sabote les relations hétérosexuelles\", 'auteur': 'Chollet,  Mona'}, {'rang': 13, 'type_de_document': 'Bande dessinée adulte', 'reservations': 521.0, 'titre': 'Le jeune acteur', 'auteur': 'Sattouf,  Riad'}, {'rang': 14, 'type_de_document': 'Bande dessinée adulte', 'reservations': 510.0, 'titre': 'Une jeunesse au Moyen-Orient, 1992-1994', 'auteur': 'Sattouf,  Riad'}, {'rang': 37, 'type_de_document': 'DVD tous publics', 'reservations': 337.0, 'titre': 'Dune', 'auteur': None}, {'rang': 58, 'type_de_document': 'DVD tous publics', 'reservations': 266.0, 'titre': 'Onoda. 10 000 nuits dans la jungle', 'auteur': None}, {'rang': 73, 'type_de_document': 'Nouveauté', 'reservations': 241.0, 'titre': 'Chien 51 : roman', 'auteur': 'Gaudé,  Laurent'}, {'rang': 87, 'type_de_document': 'Livre adulte', 'reservations': 225.0, 'titre': 'Le gosse : roman', 'auteur': 'Olmi,  Véronique'}, {'rang': 109, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 196.0, 'titre': 'Attaque au clair de lune', 'auteur': 'Oda,  Eiichiro'}, {'rang': 125, 'type_de_document': 'DVD nouveautés tous publics', 'reservations': 177.0, 'titre': 'West Side Story', 'auteur': None}, {'rang': 136, 'type_de_document': None, 'reservations': 170.0, 'titre': 'Etés anglais', 'auteur': 'Howard,  Elizabeth Jane'}, {'rang': 139, 'type_de_document': 'Bande dessinée adulte', 'reservations': 168.0, 'titre': 'Zaï zaï zaï zaï', 'auteur': 'Fabcaro'}, {'rang': 145, 'type_de_document': 'Bande dessinée adulte', 'reservations': 164.0, 'titre': 'Les piliers de la civilisation', 'auteur': 'Harari,  Yuval Noah'}, {'rang': 159, 'type_de_document': 'Livre adulte', 'reservations': 158.0, 'titre': 'Noa', 'auteur': 'Lévy,  Marc'}, {'rang': 187, 'type_de_document': 'Livre adulte', 'reservations': 144.0, 'titre': 'Les armoires vides', 'auteur': 'Ernaux,  Annie'}, {'rang': 202, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 134.0, 'titre': 'Au pays des contes défaits', 'auteur': 'Mr Tan'}, {'rang': 271, 'type_de_document': 'Livre adulte', 'reservations': 115.0, 'titre': \"Sapiens : une brève histoire de l'humanité\", 'auteur': 'Harari,  Yuval Noah'}, {'rang': 360, 'type_de_document': None, 'reservations': 100.0, 'titre': 'Et à la fin, ils meurent : la sale vérité sur les contes de fées', 'auteur': 'Lubie,  Lou'}, {'rang': 367, 'type_de_document': 'DVD tous publics', 'reservations': 99.0, 'titre': 'Madeleine Collins', 'auteur': None}, {'rang': 385, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 96.0, 'titre': \"L'escalade\", 'auteur': 'Dugomier'}, {'rang': 394, 'type_de_document': 'Nouveauté jeunesse', 'reservations': 95.0, 'titre': \"My hero academia. 8. Momo Yaoyorozu : l'envol\", 'auteur': 'Horikoshi,  Kohei'}, {'rang': 399, 'type_de_document': 'Nouveauté', 'reservations': 95.0, 'titre': 'Le poids des héros', 'auteur': 'Sala,  David'}, {'rang': 414, 'type_de_document': 'Bande dessinée adulte', 'reservations': 92.0, 'titre': \"Moi, ce que j'aime, c'est les monstres\", 'auteur': 'Ferris,  Emil'}, {'rang': 425, 'type_de_document': 'Nouveauté jeunesse', 'reservations': 91.0, 'titre': 'My hero academia. 5. Shoto Todoroki : les origines', 'auteur': 'Horikoshi,  Kohei'}, {'rang': 429, 'type_de_document': 'Livre adulte', 'reservations': 91.0, 'titre': 'Le laboureur et les mangeurs de vent : liberté intérieure et confortable servitude', 'auteur': 'Cyrulnik,  Boris'}, {'rang': 430, 'type_de_document': 'Livre adulte', 'reservations': 91.0, 'titre': 'La chambre du fils', 'auteur': 'Horst,  Jørn Lier'}, {'rang': 449, 'type_de_document': 'DVD tous publics', 'reservations': 89.0, 'titre': 'Belfast', 'auteur': None}, {'rang': 451, 'type_de_document': 'DVD nouveautés tous publics', 'reservations': 89.0, 'titre': 'Top Gun : Maverick', 'auteur': None}, {'rang': 470, 'type_de_document': 'DVD tous publics', 'reservations': 87.0, 'titre': 'Mandibules', 'auteur': None}, {'rang': 473, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 87.0, 'titre': 'Game over', 'auteur': 'Dequier,  Bruno'}, {'rang': 501, 'type_de_document': None, 'reservations': 84.0, 'titre': 'The promised neverland. 8', 'auteur': 'Shirai,  Kaiu'}, {'rang': 525, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 82.0, 'titre': 'Bergères guerrières. 3', 'auteur': 'Garnier,  Jonathan'}, {'rang': 539, 'type_de_document': 'Livre adulte', 'reservations': 81.0, 'titre': 'La chronique des Bridgerton. 5 & 6', 'auteur': 'Quinn,  Julia'}, {'rang': 559, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 80.0, 'titre': 'Oohiohioo !', 'auteur': 'Didier,  Anne'}, {'rang': 654, 'type_de_document': 'Livre adulte', 'reservations': 72.0, 'titre': 'Les possibles', 'auteur': 'Grimaldi,  Virginie'}, {'rang': 672, 'type_de_document': 'Nouveauté', 'reservations': 71.0, 'titre': \"Bonnet d'âne !\", 'auteur': 'Beaton,  M.C.'}, {'rang': 684, 'type_de_document': 'DVD nouveautés tous publics', 'reservations': 70.0, 'titre': 'Sound of Metal', 'auteur': None}, {'rang': 691, 'type_de_document': 'Livre adulte', 'reservations': 70.0, 'titre': 'Un miracle : roman', 'auteur': 'Mas,  Victoria'}, {'rang': 705, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 69.0, 'titre': \"Sous un ciel d'azur\", 'auteur': 'Horikoshi,  K?hei'}, {'rang': 715, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 69.0, 'titre': 'One Piece. 67. Cool fight', 'auteur': 'Oda,  Eiichiro'}, {'rang': 718, 'type_de_document': None, 'reservations': 69.0, 'titre': 'Si seulement...', 'auteur': 'Dequier,  Bruno'}, {'rang': 720, 'type_de_document': 'Nouveauté jeunesse', 'reservations': 68.0, 'titre': 'My hero academia. 15. Lutte contre le destin', 'auteur': 'Horikoshi,  K?hei'}, {'rang': 737, 'type_de_document': 'Livre adulte', 'reservations': 67.0, 'titre': 'Les quatre accords toltèques : la voie de la liberté personnelle', 'auteur': 'Ruiz,  Miguel'}, {'rang': 756, 'type_de_document': 'Bande dessinée ado', 'reservations': 67.0, 'titre': 'One Piece. 64', 'auteur': 'Oda,  Eiichiro'}, {'rang': 766, 'type_de_document': 'Livre adulte', 'reservations': 66.0, 'titre': 'Le rocher blanc', 'auteur': 'Hope,  Anna'}, {'rang': 794, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 65.0, 'titre': 'One Piece. 68. Alliance entre pirates', 'auteur': 'Oda,  Eiichiro'}, {'rang': 840, 'type_de_document': None, 'reservations': 62.0, 'titre': 'Le consentement', 'auteur': 'Springora,  Vanessa'}, {'rang': 860, 'type_de_document': None, 'reservations': 61.0, 'titre': 'La maison', 'auteur': 'Becker,  Emma'}, {'rang': 888, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 60.0, 'titre': 'Trop la classe !', 'auteur': 'Didier,  Anne'}, {'rang': 891, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 60.0, 'titre': \"L'atelier des sorciers. 3\", 'auteur': 'Shirahama,  Kamome'}, {'rang': 910, 'type_de_document': 'Nouveauté', 'reservations': 60.0, 'titre': \"Journal inquiet d'Istanbul. 1\", 'auteur': 'Karabulut,  Ersin'}, {'rang': 936, 'type_de_document': 'DVD tous publics', 'reservations': 59.0, 'titre': 'Peaky Blinders. Saison 6', 'auteur': None}, {'rang': 945, 'type_de_document': 'Nouveauté', 'reservations': 58.0, 'titre': 'Croire aux fauves', 'auteur': 'Martin,  Nastassja'}, {'rang': 949, 'type_de_document': 'Nouveauté', 'reservations': 58.0, 'titre': 'Solo leveling. 3', 'auteur': 'Chugong'}, {'rang': 970, 'type_de_document': 'DVD tous publics', 'reservations': 57.0, 'titre': 'The Souvenir : Part I & Part II', 'auteur': None}, {'rang': 983, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 56.0, 'titre': 'Chaperlipopette !', 'auteur': 'Mr Tan'}, {'rang': 992, 'type_de_document': 'Livre adulte', 'reservations': 56.0, 'titre': 'Tout comprendre (ou presque) sur le climat', 'auteur': 'BonPote'}, {'rang': 5, 'type_de_document': 'Livre adulte', 'reservations': 755.0, 'titre': 'La décision : roman', 'auteur': 'Tuil,  Karine'}, {'rang': 25, 'type_de_document': 'Livre adulte', 'reservations': 398.0, 'titre': 'Dans les brumes de Capelans', 'auteur': 'Norek,  Olivier'}, {'rang': 28, 'type_de_document': 'Livre adulte', 'reservations': 367.0, 'titre': \"Ton absence n'est que ténèbres : roman\", 'auteur': 'Jón Kalman Stefánsson'}, {'rang': 33, 'type_de_document': 'Livre adulte', 'reservations': 345.0, 'titre': 'Vivre avec nos morts : petit traité de consolation', 'auteur': 'Horvilleur,  Delphine'}, {'rang': 61, 'type_de_document': None, 'reservations': 261.0, 'titre': 'Faites votre glucose révolution : la formule scientifique efficace pour perdre du poids et retrouver votre énergie', 'auteur': 'Inchauspé,  Jessie'}, {'rang': 72, 'type_de_document': 'Livre adulte', 'reservations': 246.0, 'titre': 'Le pays des autres : roman', 'auteur': 'Slimani,  Leïla'}, {'rang': 75, 'type_de_document': 'Livre adulte', 'reservations': 239.0, 'titre': 'La France sous nos yeux : économie, paysages, nouveaux modes de vie', 'auteur': 'Fourquet,  Jérôme'}, {'rang': 102, 'type_de_document': 'Livre adulte', 'reservations': 200.0, 'titre': \"Les grandes oubliées : pourquoi l'histoire a effacé les femmes\", 'auteur': 'Lecoq,  Titiou'}, {'rang': 141, 'type_de_document': 'DVD nouveautés tous publics', 'reservations': 167.0, 'titre': 'Madres paralelas', 'auteur': None}, {'rang': 162, 'type_de_document': 'Bande dessinée ado', 'reservations': 156.0, 'titre': 'Naruto. 1', 'auteur': 'Kishimoto,  Masashi'}, {'rang': 217, 'type_de_document': 'Nouveauté', 'reservations': 132.0, 'titre': 'Les masques éphémères', 'auteur': 'Leon,  Donna'}, {'rang': 221, 'type_de_document': 'Livre adulte', 'reservations': 130.0, 'titre': 'Tant que le café est encore chaud : roman', 'auteur': 'Kawaguchi,  Toshikazu'}, {'rang': 229, 'type_de_document': 'DVD tous publics', 'reservations': 128.0, 'titre': 'Les  promesses', 'auteur': None}, {'rang': 233, 'type_de_document': 'Nouveauté', 'reservations': 127.0, 'titre': 'Des vivants', 'auteur': 'Meltz,  Raphaël'}, {'rang': 262, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 118.0, 'titre': 'My hero academia. 4. Celui qui avait tout', 'auteur': 'Horikoshi,  Kohei'}, {'rang': 275, 'type_de_document': 'Nouveauté', 'reservations': 114.0, 'titre': 'Madame Hayat', 'auteur': 'Altan,  Ahmet'}, {'rang': 296, 'type_de_document': 'Bande dessinée ado', 'reservations': 109.0, 'titre': 'Naruto. 13', 'auteur': 'Kishimoto,  Masashi'}, {'rang': 329, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 104.0, 'titre': 'Tiens bon !!', 'auteur': 'Oda,  Eiichiro'}, {'rang': 333, 'type_de_document': None, 'reservations': 103.0, 'titre': \"Les méduses n'ont pas d'oreilles : roman\", 'auteur': 'Rosenfeld,  Adèle'}, {'rang': 352, 'type_de_document': 'Bande dessinée ado', 'reservations': 101.0, 'titre': 'Naruto. 12', 'auteur': 'Kishimoto,  Masashi'}, {'rang': 366, 'type_de_document': 'Bande dessinée adulte', 'reservations': 99.0, 'titre': 'Choses sérieuses', 'auteur': 'Oseman,  Alice'}, {'rang': 370, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 98.0, 'titre': 'Demon slayer : Kimetsu no yaiba. 12', 'auteur': 'Gotouge,  Koyoharu'}, {'rang': 407, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 94.0, 'titre': 'Coeur du passé', 'auteur': 'Sobral,  Patrick'}, {'rang': 416, 'type_de_document': 'Livre adulte', 'reservations': 92.0, 'titre': 'Chavirer : roman', 'auteur': 'Lafon,  Lola'}, {'rang': 446, 'type_de_document': 'DVD nouveautés tous publics', 'reservations': 89.0, 'titre': 'Eugénie Grandet', 'auteur': None}, {'rang': 503, 'type_de_document': 'Bande dessinée adulte', 'reservations': 84.0, 'titre': 'The promised Neverland. 14', 'auteur': 'Shirai,  Kaiu'}, {'rang': 564, 'type_de_document': 'Livre ado', 'reservations': 79.0, 'titre': 'Le roi maléfique', 'auteur': 'Black,  Holly'}, {'rang': 572, 'type_de_document': None, 'reservations': 79.0, 'titre': \"La fin d'une ère\", 'auteur': 'Howard,  Elizabeth Jane'}, {'rang': 626, 'type_de_document': 'Livre jeunesse', 'reservations': 74.0, 'titre': 'Harry Potter et la chambre des secrets', 'auteur': 'Rowling,  Joanne Kathleen'}, {'rang': 630, 'type_de_document': None, 'reservations': 74.0, 'titre': 'Les dieux sont amour', 'auteur': 'Sobral,  Patrick'}, {'rang': 637, 'type_de_document': None, 'reservations': 73.0, 'titre': 'The promised Neverland. 13', 'auteur': 'Shirai,  Kaiu'}, {'rang': 647, 'type_de_document': None, 'reservations': 73.0, 'titre': 'Vernon Subutex. 1', 'auteur': 'Despentes,  Virginie'}, {'rang': 677, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 71.0, 'titre': 'One Piece. 55. Des travs en enfer', 'auteur': 'Oda,  Eiichiro'}, {'rang': 682, 'type_de_document': None, 'reservations': 70.0, 'titre': \"C'est comme ça que je disparais\", 'auteur': 'Malle,  Mirion'}, {'rang': 690, 'type_de_document': 'DVD nouveautés tous publics', 'reservations': 70.0, 'titre': 'Twist à Bamako', 'auteur': None}, {'rang': 719, 'type_de_document': 'Livre adulte', 'reservations': 68.0, 'titre': 'Kilomètre zéro : le chemin du bonheur', 'auteur': 'Ankaoua,  Maud'}, {'rang': 726, 'type_de_document': 'Nouveauté', 'reservations': 68.0, 'titre': 'Solo leveling. 5', 'auteur': 'Chugong'}, {'rang': 732, 'type_de_document': 'Bande dessinée ado', 'reservations': 68.0, 'titre': 'Naruto. 30', 'auteur': 'Kishimoto,  Masashi'}, {'rang': 757, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 67.0, 'titre': \"L'opération Dressrosa S.O.P.\", 'auteur': 'Oda,  Eiichiro'}, {'rang': 759, 'type_de_document': 'Bande dessinée adulte', 'reservations': 66.0, 'titre': 'The promised neverland. 1', 'auteur': 'Shirai,  Kaiu'}, {'rang': 762, 'type_de_document': 'Nouveauté', 'reservations': 66.0, 'titre': 'La vérité sur la lumière', 'auteur': 'Auður Ava Ólafsdóttir'}, {'rang': 769, 'type_de_document': 'Bande dessinée ado', 'reservations': 66.0, 'titre': 'Naruto. 21', 'auteur': 'Kishimoto,  Masashi'}, {'rang': 799, 'type_de_document': 'Livre adulte', 'reservations': 64.0, 'titre': 'Pouilles', 'auteur': None}, {'rang': 801, 'type_de_document': 'Bande dessinée jeunesse', 'reservations': 64.0, 'titre': 'Blue lock. 1', 'auteur': 'Kaneshiro,  Muneyuki'}]}\n"
     ]
    }
   ],
   "source": [
    "wb_bibli = response.json()  # Utilisation de .json() sur l'objet réponse\n",
    "print(\"Structure du JSON :\")\n",
    "print(wb_bibli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du dataframe.\n",
    "On remarque qu'il y a parfois des catégories qui ne donnent pas assez d'information sur le type d'ouvrage, à l'image de \"Nouveauté\", ou encore de \"None\". Nous pensons qu'il peut être pertinent d'étudier l'impact différé des prix et de l'exposition sur Youtube selon le genre d'ouvrage , dans la limite du possible. Ainsi, nous avons décidé d'utiliser des méthodes de scraping pour compléter la base. Avant de faire cela, nous avons décidé d'enlever de la base tous les ouvrages de type DVDs, ces derniers ne nous intéressant pas dans le cadre de notre projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rang</th>\n",
       "      <th>type_de_document</th>\n",
       "      <th>reservations</th>\n",
       "      <th>titre</th>\n",
       "      <th>auteur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>Livre adulte</td>\n",
       "      <td>522.0</td>\n",
       "      <td>Réinventer l'amour : comment le patriarcat sab...</td>\n",
       "      <td>Chollet,  Mona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>Bande dessinée adulte</td>\n",
       "      <td>521.0</td>\n",
       "      <td>Le jeune acteur</td>\n",
       "      <td>Sattouf,  Riad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>Bande dessinée adulte</td>\n",
       "      <td>510.0</td>\n",
       "      <td>Une jeunesse au Moyen-Orient, 1992-1994</td>\n",
       "      <td>Sattouf,  Riad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>DVD tous publics</td>\n",
       "      <td>337.0</td>\n",
       "      <td>Dune</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>DVD tous publics</td>\n",
       "      <td>266.0</td>\n",
       "      <td>Onoda. 10 000 nuits dans la jungle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73</td>\n",
       "      <td>Nouveauté</td>\n",
       "      <td>241.0</td>\n",
       "      <td>Chien 51 : roman</td>\n",
       "      <td>Gaudé,  Laurent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87</td>\n",
       "      <td>Livre adulte</td>\n",
       "      <td>225.0</td>\n",
       "      <td>Le gosse : roman</td>\n",
       "      <td>Olmi,  Véronique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>109</td>\n",
       "      <td>Bande dessinée jeunesse</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Attaque au clair de lune</td>\n",
       "      <td>Oda,  Eiichiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>125</td>\n",
       "      <td>DVD nouveautés tous publics</td>\n",
       "      <td>177.0</td>\n",
       "      <td>West Side Story</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>136</td>\n",
       "      <td>None</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Etés anglais</td>\n",
       "      <td>Howard,  Elizabeth Jane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>139</td>\n",
       "      <td>Bande dessinée adulte</td>\n",
       "      <td>168.0</td>\n",
       "      <td>Zaï zaï zaï zaï</td>\n",
       "      <td>Fabcaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>145</td>\n",
       "      <td>Bande dessinée adulte</td>\n",
       "      <td>164.0</td>\n",
       "      <td>Les piliers de la civilisation</td>\n",
       "      <td>Harari,  Yuval Noah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rang             type_de_document  reservations  \\\n",
       "0     12                 Livre adulte         522.0   \n",
       "1     13        Bande dessinée adulte         521.0   \n",
       "2     14        Bande dessinée adulte         510.0   \n",
       "3     37             DVD tous publics         337.0   \n",
       "4     58             DVD tous publics         266.0   \n",
       "5     73                    Nouveauté         241.0   \n",
       "6     87                 Livre adulte         225.0   \n",
       "7    109      Bande dessinée jeunesse         196.0   \n",
       "8    125  DVD nouveautés tous publics         177.0   \n",
       "9    136                         None         170.0   \n",
       "10   139        Bande dessinée adulte         168.0   \n",
       "11   145        Bande dessinée adulte         164.0   \n",
       "\n",
       "                                                titre                   auteur  \n",
       "0   Réinventer l'amour : comment le patriarcat sab...           Chollet,  Mona  \n",
       "1                                     Le jeune acteur           Sattouf,  Riad  \n",
       "2             Une jeunesse au Moyen-Orient, 1992-1994           Sattouf,  Riad  \n",
       "3                                                Dune                     None  \n",
       "4                  Onoda. 10 000 nuits dans la jungle                     None  \n",
       "5                                    Chien 51 : roman          Gaudé,  Laurent  \n",
       "6                                    Le gosse : roman         Olmi,  Véronique  \n",
       "7                            Attaque au clair de lune           Oda,  Eiichiro  \n",
       "8                                     West Side Story                     None  \n",
       "9                                        Etés anglais  Howard,  Elizabeth Jane  \n",
       "10                                    Zaï zaï zaï zaï                  Fabcaro  \n",
       "11                     Les piliers de la civilisation      Harari,  Yuval Noah  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_bibli= pd.json_normalize(wb_bibli['results'])\n",
    "df_bibli.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, il est nécessaire de prendre connaissance de toutes les catégories pour savoir lesquelles remplacer, desquelles se débarasser..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Livre adulte' 'Bande dessinée adulte' 'DVD tous publics' 'Nouveauté'\n",
      " 'Bande dessinée jeunesse' 'DVD nouveautés tous publics' None\n",
      " 'Nouveauté jeunesse' 'Bande dessinée ado' 'Livre ado' 'Livre jeunesse']\n"
     ]
    }
   ],
   "source": [
    "print(df_bibli[\"type_de_document\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme annoncé, on ne garde que les catégories qui nous intéresse ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = [\"Livre adulte\", \"Bande dessinée adulte\", \"Nouveauté\", \"Bande dessinée jeunesse\", \"Nouveauté jeunesse\",\n",
    " \"Bande dessinée ado\", \"Livre ado\", \"Livre jeunesse\", None]\n",
    "df_bibli= df_bibli[df_bibli[\"type_de_document\"].isin(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rang</th>\n",
       "      <th>type_de_document</th>\n",
       "      <th>reservations</th>\n",
       "      <th>titre</th>\n",
       "      <th>auteur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>Livre adulte</td>\n",
       "      <td>522.0</td>\n",
       "      <td>Réinventer l'amour : comment le patriarcat sab...</td>\n",
       "      <td>Chollet,  Mona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>Bande dessinée adulte</td>\n",
       "      <td>521.0</td>\n",
       "      <td>Le jeune acteur</td>\n",
       "      <td>Sattouf,  Riad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>Bande dessinée adulte</td>\n",
       "      <td>510.0</td>\n",
       "      <td>Une jeunesse au Moyen-Orient, 1992-1994</td>\n",
       "      <td>Sattouf,  Riad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73</td>\n",
       "      <td>Nouveauté</td>\n",
       "      <td>241.0</td>\n",
       "      <td>Chien 51 : roman</td>\n",
       "      <td>Gaudé,  Laurent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87</td>\n",
       "      <td>Livre adulte</td>\n",
       "      <td>225.0</td>\n",
       "      <td>Le gosse : roman</td>\n",
       "      <td>Olmi,  Véronique</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rang       type_de_document  reservations  \\\n",
       "0    12           Livre adulte         522.0   \n",
       "1    13  Bande dessinée adulte         521.0   \n",
       "2    14  Bande dessinée adulte         510.0   \n",
       "5    73              Nouveauté         241.0   \n",
       "6    87           Livre adulte         225.0   \n",
       "\n",
       "                                               titre            auteur  \n",
       "0  Réinventer l'amour : comment le patriarcat sab...    Chollet,  Mona  \n",
       "1                                    Le jeune acteur    Sattouf,  Riad  \n",
       "2            Une jeunesse au Moyen-Orient, 1992-1994    Sattouf,  Riad  \n",
       "5                                   Chien 51 : roman   Gaudé,  Laurent  \n",
       "6                                   Le gosse : roman  Olmi,  Véronique  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bibli.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'il y a beaucoup de livres dans notre base dont le type n'est pas renseigné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rang    type_de_document  reservations  \\\n",
      "5     73           Nouveauté         241.0   \n",
      "9    136                None         170.0   \n",
      "16   360                None         100.0   \n",
      "19   394  Nouveauté jeunesse          95.0   \n",
      "20   399           Nouveauté          95.0   \n",
      "22   425  Nouveauté jeunesse          91.0   \n",
      "29   501                None          84.0   \n",
      "34   672           Nouveauté          71.0   \n",
      "39   718                None          69.0   \n",
      "40   720  Nouveauté jeunesse          68.0   \n",
      "45   840                None          62.0   \n",
      "46   860                None          61.0   \n",
      "49   910           Nouveauté          60.0   \n",
      "51   945           Nouveauté          58.0   \n",
      "52   949           Nouveauté          58.0   \n",
      "60    61                None         261.0   \n",
      "66   217           Nouveauté         132.0   \n",
      "69   233           Nouveauté         127.0   \n",
      "71   275           Nouveauté         114.0   \n",
      "74   333                None         103.0   \n",
      "83   572                None          79.0   \n",
      "85   630                None          74.0   \n",
      "86   637                None          73.0   \n",
      "87   647                None          73.0   \n",
      "89   682                None          70.0   \n",
      "92   726           Nouveauté          68.0   \n",
      "96   762           Nouveauté          66.0   \n",
      "\n",
      "                                                titre                   auteur  \n",
      "5                                    Chien 51 : roman          Gaudé,  Laurent  \n",
      "9                                        Etés anglais  Howard,  Elizabeth Jane  \n",
      "16  Et à la fin, ils meurent : la sale vérité sur ...              Lubie,  Lou  \n",
      "19      My hero academia. 8. Momo Yaoyorozu : l'envol        Horikoshi,  Kohei  \n",
      "20                                 Le poids des héros             Sala,  David  \n",
      "22  My hero academia. 5. Shoto Todoroki : les orig...        Horikoshi,  Kohei  \n",
      "29                          The promised neverland. 8            Shirai,  Kaiu  \n",
      "34                                     Bonnet d'âne !            Beaton,  M.C.  \n",
      "39                                    Si seulement...          Dequier,  Bruno  \n",
      "40       My hero academia. 15. Lutte contre le destin        Horikoshi,  K?hei  \n",
      "45                                    Le consentement      Springora,  Vanessa  \n",
      "46                                          La maison            Becker,  Emma  \n",
      "49                      Journal inquiet d'Istanbul. 1        Karabulut,  Ersin  \n",
      "51                                  Croire aux fauves       Martin,  Nastassja  \n",
      "52                                   Solo leveling. 3                  Chugong  \n",
      "60  Faites votre glucose révolution : la formule s...       Inchauspé,  Jessie  \n",
      "66                              Les masques éphémères             Leon,  Donna  \n",
      "69                                        Des vivants          Meltz,  Raphaël  \n",
      "71                                       Madame Hayat            Altan,  Ahmet  \n",
      "74           Les méduses n'ont pas d'oreilles : roman        Rosenfeld,  Adèle  \n",
      "83                                   La fin d'une ère  Howard,  Elizabeth Jane  \n",
      "85                               Les dieux sont amour         Sobral,  Patrick  \n",
      "86                         The promised Neverland. 13            Shirai,  Kaiu  \n",
      "87                                  Vernon Subutex. 1     Despentes,  Virginie  \n",
      "89                    C'est comme ça que je disparais           Malle,  Mirion  \n",
      "92                                   Solo leveling. 5                  Chugong  \n",
      "96                           La vérité sur la lumière    Auður Ava Ólafsdóttir  \n"
     ]
    }
   ],
   "source": [
    "nouveau = [\"Nouveauté\", \"Nouveauté jeunesse\", None]\n",
    "df_bibli_nouveau =  df_bibli[df_bibli[\"type_de_document\"].isin(nouveau)]\n",
    "print(df_bibli_nouveau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le scrapping, nous avons choisi de le faire sur livraddict puisqu'il s'agit d'un site où tous les titres sont en français, avec un type de fonction recherche pratique pour scrapper. Sur ce site sont de plus décrits tous les livres connus avec des catégorie toujours indiquées avec un code similaire.\n",
    "\n",
    "Pour ce faire, nous avons d'abord générer une URL de recherche sur livraddict. On scrappe la page pour récupérer l'URL du premier résultat de la recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Fonction pour rechercher un livre sur Babelio et accéder à la page du premier résultat\n",
    "def search_livraddict(book_title):\n",
    "    # URL de recherche sur Livraddict\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    search_url = f'https://www.livraddict.com/search.php?t={book_title}]'\n",
    "\n",
    "    # Faire une requête pour récupérer la page des résultats de recherche\n",
    "    response = requests.get(search_url, headers=headers).content\n",
    "    # Trouver le premier élément correspondant au lien d'un résultat\n",
    "    page = BeautifulSoup(response, \"html.parser\")\n",
    "    first_result = page.select_one('.listing_recherche li .item_photo a')\n",
    "    if first_result is not None:\n",
    "        url = first_result['href']\n",
    "        full_url = f\"https://www.livraddict.com{url}\"\n",
    "        return full_url\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On scrappe cette fois la page du premier résultat de la recherche précédente pour trouver les informations du livre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_livre(info):\n",
    "    if info is None:\n",
    "        type_livre=\"Nom du livre pas trouvé sur Livraddict\"\n",
    "    else:\n",
    "        # Normaliser les chaînes (supprimer les espaces et convertir en minuscules)\n",
    "        info_0_normalized = info[0].strip().lower()\n",
    "        info_1_normalized = info[1].strip().lower()\n",
    "\n",
    "        if info_0_normalized in [\"album\", \"artbook/beau livre\", \"bande-dessinée\", \"comics\", \"manga\"] and info_1_normalized in [\"petite enfance\", \"enfance\"]:\n",
    "            type_livre = \"Bande dessinée jeunesse\"\n",
    "\n",
    "        elif info_0_normalized in [\"album\", \"artbook/beau livre\", \"bande-dessinée\", \"comics\", \"manga\"] and info_1_normalized in [\"adolescence\"]:\n",
    "            type_livre = \"Bande dessinée ado\"\n",
    "\n",
    "        elif info_0_normalized in [\"album\", \"artbook/beau livre\", \"bande-dessinée\", \"comics\", \"manga\"] and info_1_normalized in [\"young adult\", \"adulte\"]:\n",
    "            type_livre = \"Bande dessinée ado\"\n",
    "\n",
    "        elif info_0_normalized in [\"correspondance\", \"documentaire\", \"essai\", \"livre pratique\", \"nouvelle(s)\", \"poésie\", \"roman\", \"théâtre\"] and info_1_normalized in [\"petite enfance\", \"enfance\"]:\n",
    "            type_livre = \"Livre jeunesse\"\n",
    "\n",
    "        elif info_0_normalized in [\"correspondance\", \"documentaire\", \"essai\", \"livre pratique\", \"nouvelle(s)\", \"poésie\", \"roman\", \"théâtre\"] and info_1_normalized in [\"adolescence\"]:\n",
    "            type_livre = \"Livre ado\"\n",
    "\n",
    "        elif info_0_normalized in [\"correspondance\", \"documentaire\", \"essai\", \"livre pratique\", \"nouvelle(s)\", \"poésie\", \"roman\", \"théâtre\"] and info_1_normalized in [\"young adult\", \"adulte\"]:\n",
    "            type_livre = \"Livre adulte\"\n",
    "\n",
    "        else: type_livre= \"Introuvable\"\n",
    "    return type_livre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_type(url):\n",
    "    if url is not None:\n",
    "        headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "        response = requests.get(url, headers=headers).content\n",
    "        page = BeautifulSoup(response, \"html.parser\")\n",
    "        c_format= page.find(\"div\", class_= \"book_classif book_format mr1\")\n",
    "        c_lectorat= page.find(\"div\", class_=\"book_classif book_lectorat mr1\")\n",
    "        if c_format:\n",
    "            a_format = c_format.find(\"a\")\n",
    "            format_livre = a_format.text\n",
    "        else:\n",
    "            format_livre = \"Non renseigné\"\n",
    "        if c_lectorat:\n",
    "            a_lectorat = c_lectorat.find(\"a\")\n",
    "            lectorat = a_lectorat.text\n",
    "        else: \n",
    "            lectorat = \"Non renseigné\"\n",
    "        info = [format_livre, lectorat]\n",
    "        return info\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'une fonction qui assemble ces deux fonctions pour qu'à partir seulement d'un titre, on obtienne le type du livre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_type_livre(titre):\n",
    "    livre = titre.split()\n",
    "    titre_livre = \"\"\n",
    "    for i in range(0, len(livre) - 1):\n",
    "        titre_livre = titre_livre + livre[i] + \"+\"\n",
    "    titre_livre = titre_livre + livre[len(livre)-1]\n",
    "    url = search_livraddict(titre_livre)\n",
    "    infos = obtain_type(url)\n",
    "    type_de_livre = type_livre(infos)\n",
    "    return type_de_livre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on définit pour quel type de titre quelle fonction s'applique et pour quels livres on va chercher leur type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_search(row):\n",
    "    nouveau = [\"Nouveauté\", \"Nouveauté jeunesse\", None]\n",
    "    if row[\"type_de_document\"] in nouveau:\n",
    "        parties = row[\"titre\"].split(\".\")\n",
    "        parties_bis = row[\"titre\"].split(\":\")\n",
    "\n",
    "        #pour les séries avec nom de série, numéro tome, nom du tome\n",
    "        if len(parties)==3:\n",
    "            saga = parties[0].strip()\n",
    "            tome = parties[1].strip()\n",
    "            nom = parties[2].strip()\n",
    "            if int(tome) < 10:\n",
    "                type_de_livre = search_type_livre(saga+\"+\"+\"tome\"+\"+\"+\"0\"+tome)\n",
    "                if type_de_livre == \"Nom du livre pas trouvé sur Livraddict\":\n",
    "                    type_de_livre = search_type_livre(saga+\"+\"+\"tome\"+\"+\"+tome)\n",
    "            elif int(tome)>= 10:\n",
    "                type_de_livre = search_type_livre(saga+\"+\"+\"tome\"+\"+\"+tome)\n",
    "        \n",
    "        #pour les séries avec que nom de série et numéro de tome\n",
    "        elif len(parties)==2:\n",
    "            saga = parties[0].strip()\n",
    "            tome = parties[1].strip()\n",
    "            if int(tome) < 10:\n",
    "                type_de_livre = search_type_livre(saga+\"+\"+\"tome\"+\"+\"+\"0\"+tome)\n",
    "                if type_de_livre == \"Nom du livre pas trouvé sur Livraddict\":\n",
    "                    type_de_livre = search_type_livre(saga+\"+\"+\"tome\"+\"+\"+tome)\n",
    "            elif int(tome)>= 10:\n",
    "                type_de_livre = search_type_livre(saga+\"+\"+\"tome\"+\"+\"+tome)\n",
    "        \n",
    "        #pour les livre où il y a écrit le genre après le titre\n",
    "        elif len(parties_bis) == 2:\n",
    "            type_de_livre = search_type_livre(row[\"titre\"])\n",
    "            if type_de_livre == \"Nom du livre pas trouvé sur Livraddict\":\n",
    "                nom = parties_bis[0].strip()\n",
    "                type_de_livre = search_type_livre(nom)\n",
    "\n",
    "        else:\n",
    "            type_de_livre = search_type_livre(row[\"titre\"])\n",
    "        return type_de_livre\n",
    "\n",
    "\n",
    "    else:\n",
    "        return row[\"type_de_document\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique enfin la fonction à notre dataframe. La fonction prend entre 1 et 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bibli['type_de_document'] = df_bibli.apply(apply_search, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde si des livres n'ont pas été trouvés. On remarque que tous les types de livre ont bien été trouvé ! Hourra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [rang, type_de_document, reservations, titre, auteur]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "erreur_recherche = [\"Nom du livre pas trouvé sur Livraddict\"]\n",
    "df_bibli_erreur =  df_bibli[df_bibli[\"type_de_document\"].isin(erreur_recherche)]\n",
    "print(df_bibli_erreur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [rang, type_de_document, reservations, titre, auteur]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "autre_erreur = [\"Introuvable\"]\n",
    "df_bibli_int =  df_bibli[df_bibli[\"type_de_document\"].isin(erreur_recherche)]\n",
    "print(df_bibli_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on veut réordonner la base de manière à pouvoir mettre des rangs sans trous dans les numéros sur cette dernière. On commence pour ce faire par l'ordonner selon le rang, afin ensuite de numéroter les lignes dans l'ordre d'affichage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bibli = df_bibli.sort_values(by=\"rang\")\n",
    "df_bibli = df_bibli.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "nb_books = df_bibli[df_bibli['titre'].notna()].shape[0]\n",
    "print(nb_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bibli['Classement bibliothèque'] = None  # Initialiser avec None\n",
    "df_bibli['Top bibliothèque'] = None\n",
    "\n",
    "# Remplir `classement` uniquement jusqu'à l'index 85\n",
    "max_index = 85  # Exemple d'index limite\n",
    "df_bibli.loc[df_bibli.index <= max_index, 'Classement bibliothèque'] = range(1, min(len(df_bibli), max_index + 1) + 1)\n",
    "df_bibli.loc[df_bibli.index <= max_index, 'Top bibliothèque'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie pour finir le début de notre base pour s'assurer que notre variable marche bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rang</th>\n",
       "      <th>type_de_document</th>\n",
       "      <th>reservations</th>\n",
       "      <th>titre</th>\n",
       "      <th>auteur</th>\n",
       "      <th>Classement bibliothèque</th>\n",
       "      <th>Top bibliothèque</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Livre adulte</td>\n",
       "      <td>755.0</td>\n",
       "      <td>La décision : roman</td>\n",
       "      <td>Tuil,  Karine</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Livre adulte</td>\n",
       "      <td>522.0</td>\n",
       "      <td>Réinventer l'amour : comment le patriarcat sab...</td>\n",
       "      <td>Chollet,  Mona</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Bande dessinée adulte</td>\n",
       "      <td>521.0</td>\n",
       "      <td>Le jeune acteur</td>\n",
       "      <td>Sattouf,  Riad</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>Bande dessinée adulte</td>\n",
       "      <td>510.0</td>\n",
       "      <td>Une jeunesse au Moyen-Orient, 1992-1994</td>\n",
       "      <td>Sattouf,  Riad</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>Livre adulte</td>\n",
       "      <td>398.0</td>\n",
       "      <td>Dans les brumes de Capelans</td>\n",
       "      <td>Norek,  Olivier</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rang       type_de_document  reservations  \\\n",
       "0     5           Livre adulte         755.0   \n",
       "1    12           Livre adulte         522.0   \n",
       "2    13  Bande dessinée adulte         521.0   \n",
       "3    14  Bande dessinée adulte         510.0   \n",
       "4    25           Livre adulte         398.0   \n",
       "\n",
       "                                               titre           auteur  \\\n",
       "0                                La décision : roman    Tuil,  Karine   \n",
       "1  Réinventer l'amour : comment le patriarcat sab...   Chollet,  Mona   \n",
       "2                                    Le jeune acteur   Sattouf,  Riad   \n",
       "3            Une jeunesse au Moyen-Orient, 1992-1994   Sattouf,  Riad   \n",
       "4                        Dans les brumes de Capelans  Norek,  Olivier   \n",
       "\n",
       "  Classement bibliothèque Top bibliothèque  \n",
       "0                       1                1  \n",
       "1                       2                1  \n",
       "2                       3                1  \n",
       "3                       4                1  \n",
       "4                       5                1  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bibli.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un fichier csv pour plus tard fusionner les bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bibli.to_csv(\"Les livres les plus empruntés à Paris.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des tops des livres populaires de plusieurs sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 23 livres les plus populaires en 2023 sur Babelio, on ajoute une colonne indicatrice pour qu'il y ait un 1 lors du merge de toutes les tables pour les livres qui sont dans le top Babelio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL de la page à scrapper\n",
    "babelio_top_2023 = \"https://www.babelio.com/article/2543/Les-23-livres-les-plus-populaires-de-2023\"\n",
    "\n",
    "# on fait la requête HTTP vers la page\n",
    "response = requests.get(babelio_top_2023)\n",
    "\n",
    "# On utilise l'encodage détecté par requests\n",
    "response.encoding = response.apparent_encoding\n",
    "\n",
    "if response.status_code == 200:  # Vérifie que le site autorise le scraping\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Liste pour stocker les données extraites\n",
    "    babelio_data = []\n",
    "\n",
    "    # On trouve toutes les sections contenant les livres\n",
    "    titles_sections = soup.find_all('span', class_='titre_global')\n",
    "    for section in titles_sections:\n",
    "        # On extrait le titre\n",
    "        title_tag = section.find('a')\n",
    "        title = title_tag.text.strip() if title_tag else None\n",
    "\n",
    "        # On extrait l'auteur\n",
    "        author_text = section.text.split(\"de\")[-1].strip() if \"de\" in section.text else None\n",
    "        author = author_text.split(\"\\n\")[0] if author_text else None\n",
    "\n",
    "        # Ajouter aux données si titre et auteur sont présents\n",
    "        if title and author:\n",
    "            babelio_data.append([title, author])\n",
    "\n",
    "    # On convertie les données en DataFrame\n",
    "    df_babelio_data = pd.DataFrame(babelio_data, columns=['Titre', 'Auteur'])\n",
    "\n",
    "    # Ajout de la colonne indicatrice \"top_babelio\"\n",
    "    df_babelio_data['top_babelio'] = 1\n",
    "else:\n",
    "    print(\"Erreur dans la requête\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde si tout va bien avec notre dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Titre                 Auteur  \\\n",
      "0                                  Les Aiguilles dor       Michael McDowell   \n",
      "1                                        Triste tigre            Neige Sinno   \n",
      "2                                     La Petite-Fille       Bernhard Schlink   \n",
      "3       La prochaine fois que tu mordras la poussière       Panayotis Pascot   \n",
      "4                                       Conte de fées           Stephen King   \n",
      "5                                 Un il dans la nuit         Bernard Minier   \n",
      "6                                  Un abri de fortune  fortune d'Agnès Ledig   \n",
      "7                              Trois vies par semaine           Michel Bussi   \n",
      "8   Im not your soulmate, tome 1 : The Perfect Match              Lyla Mars   \n",
      "9                                        Sur la dalle            Fred Vargas   \n",
      "10            Le Bureau d'éclaircissement des destins          Gaëlle Nohant   \n",
      "11  Les Sept Surs, tome 8 : Atlas, l'histoire de ...          Lucinda Riley   \n",
      "12     Seasons, tome 1 : Un automne pour te pardonner      Morgane Moncomble   \n",
      "13                                           L'Enragé         Sorj Chalandon   \n",
      "14                      Ceci n'est pas un fait divers        Philippe Besson   \n",
      "15                                 La Femme de ménage                      n   \n",
      "16                                          La Faille        Franck Thilliez   \n",
      "17                                    Captive, tome 2           Sarah Rivens   \n",
      "18                                      Une belle vie      Virginie Grimaldi   \n",
      "19                            Le Silence et la Colère        Pierre Lemaitre   \n",
      "20                                      À tout jamais         Colleen Hoover   \n",
      "21                                   Veiller sur elle   Jean-Baptiste Andrea   \n",
      "22                        Les Femmes du bout du monde       Mélissa Da Costa   \n",
      "\n",
      "    top_babelio  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n",
      "5             1  \n",
      "6             1  \n",
      "7             1  \n",
      "8             1  \n",
      "9             1  \n",
      "10            1  \n",
      "11            1  \n",
      "12            1  \n",
      "13            1  \n",
      "14            1  \n",
      "15            1  \n",
      "16            1  \n",
      "17            1  \n",
      "18            1  \n",
      "19            1  \n",
      "20            1  \n",
      "21            1  \n",
      "22            1  \n"
     ]
    }
   ],
   "source": [
    "print(df_babelio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'il y a quelques problèmes, mais c'est rapide à corriger à la main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_babelio_data.loc[df_babelio_data['Titre'] == \"Un il dans la nuit\",'Titre'] = 'Un oeil dans la nuit'\n",
    "df_babelio_data.loc[df_babelio_data['Auteur'] == \"fortune d'Agnès Ledig\",'Auteur'] = 'Agnès Ledig'\n",
    "df_babelio_data.loc[df_babelio_data['Titre'] == \"La Femme de ménage\",'Auteur'] = 'Freida McFadden'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Titre                Auteur  \\\n",
      "0                                  Les Aiguilles dor      Michael McDowell   \n",
      "1                                        Triste tigre           Neige Sinno   \n",
      "2                                     La Petite-Fille      Bernhard Schlink   \n",
      "3       La prochaine fois que tu mordras la poussière      Panayotis Pascot   \n",
      "4                                       Conte de fées          Stephen King   \n",
      "5                                Un oeil dans la nuit        Bernard Minier   \n",
      "6                                  Un abri de fortune           Agnès Ledig   \n",
      "7                              Trois vies par semaine          Michel Bussi   \n",
      "8   Im not your soulmate, tome 1 : The Perfect Match             Lyla Mars   \n",
      "9                                        Sur la dalle           Fred Vargas   \n",
      "10            Le Bureau d'éclaircissement des destins         Gaëlle Nohant   \n",
      "11  Les Sept Surs, tome 8 : Atlas, l'histoire de ...         Lucinda Riley   \n",
      "12     Seasons, tome 1 : Un automne pour te pardonner     Morgane Moncomble   \n",
      "13                                           L'Enragé        Sorj Chalandon   \n",
      "14                      Ceci n'est pas un fait divers       Philippe Besson   \n",
      "15                                 La Femme de ménage       Freida McFadden   \n",
      "16                                          La Faille       Franck Thilliez   \n",
      "17                                    Captive, tome 2          Sarah Rivens   \n",
      "18                                      Une belle vie     Virginie Grimaldi   \n",
      "19                            Le Silence et la Colère       Pierre Lemaitre   \n",
      "20                                      À tout jamais        Colleen Hoover   \n",
      "21                                   Veiller sur elle  Jean-Baptiste Andrea   \n",
      "22                        Les Femmes du bout du monde      Mélissa Da Costa   \n",
      "\n",
      "    top_babelio  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n",
      "5             1  \n",
      "6             1  \n",
      "7             1  \n",
      "8             1  \n",
      "9             1  \n",
      "10            1  \n",
      "11            1  \n",
      "12            1  \n",
      "13            1  \n",
      "14            1  \n",
      "15            1  \n",
      "16            1  \n",
      "17            1  \n",
      "18            1  \n",
      "19            1  \n",
      "20            1  \n",
      "21            1  \n",
      "22            1  \n"
     ]
    }
   ],
   "source": [
    "print(df_babelio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du fichier csv pour plus tard merge les bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_babelio_data.to_csv(\"23 livres les plus lus Babelio.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des livres les plus vendus à la Fnac entre janvier et décembre 2023. Nous avons pensé que ce serait pertinent de récupérer les Best sellers afin de diminuer le biais des autres données dont nous possédons ( les personnes fréquentant les bibliothèques de Paris ou inscrivant leurs lectures sur Babelio étant un échantillon très biaisé)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_titles_and_authors(url, month): # cette fonction prend pour argument l'url et le mois\n",
    "    response = requests.get(url)\n",
    "    response.encoding = \"utf-8\"  # pour garantir le bon encodage\n",
    "    data = [] #on crée une liste vide où on va mettre les données scrappées\n",
    "\n",
    "    if response.status_code == 200:  # On vérifie si la requête est un succès\n",
    "        soup = BeautifulSoup(response.text, 'html.parser') #on précie la manière de parcourir le code\n",
    "\n",
    "        # On recherche toutes les balises <h2> avec la classe \"title-part\"\n",
    "        titles = soup.find_all('h2', class_='title-part')\n",
    "        for title in titles:\n",
    "            raw_text = title.text.strip()  # Texte brut pour manipulation\n",
    "\n",
    "            # Debugging : Afficher le texte brut\n",
    "            print(f\"Texte brut extrait : {raw_text}\")\n",
    "\n",
    "            # On fait un regex pour extraire les informations\n",
    "            match = re.match(r'^(\\d+)\\s[–—]\\s(.+?)\\s[–—]\\s(.+?)(?:[,/]\\s(.+?))?\\s\\((.+?)\\)$', raw_text)\n",
    "            if match:\n",
    "                classement = match.group(1).strip()  # Classement\n",
    "                titre = match.group(2).strip()  # Titre\n",
    "                auteur_principal = match.group(3).strip()  # Auteur principal\n",
    "                co_auteur_raw = match.group(4).strip() if match.group(4) else None  # Co-auteur brut (facultatif)\n",
    "                maison_edition = match.group(5).strip()  # Maison d'édition\n",
    "\n",
    "                # Traitement des co-auteurs pour les séparer en liste\n",
    "                co_auteurs = []\n",
    "                if co_auteur_raw:\n",
    "                    co_auteurs = re.split(r',\\s|/\\s', co_auteur_raw)  # Diviser par virgule ou slash\n",
    "\n",
    "                # Ajouter les informations dans la liste (sans maison d'édition)\n",
    "                data.append([month, classement, titre, auteur_principal] + co_auteurs[:2])  # Max 2 co-auteurs\n",
    "    else:\n",
    "        print(f\"Erreur lors du scraping de {month}: Status code {response.status_code}\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste des URL à scrapper pour récupérer tous les bestsellers de 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_months = [\n",
    "    (\"https://leclaireur.fnac.com/selection/cp50350-top-10-les-best-sellers-du-mois-de-janvier-2023/\", \"Janvier\"),\n",
    "    (\"https://leclaireur.fnac.com/selection/cp50709-top-10-les-best-sellers-du-mois-de-fevrier-2023/\", \"Février\"),\n",
    "    (\"https://leclaireur.fnac.com/selection/cp43551-top-10-les-best-sellers-de-mars-2023/\", \"Mars\"),\n",
    "    (\"https://leclaireur.fnac.com/selection/cp44047-top-10-les-best-sellers-davril-2023/\", \"Avril\"),\n",
    "    (\"https://leclaireur.fnac.com/selection/cp48182-top-10-les-best-sellers-de-mai-2023/\", \"Mai\"),\n",
    "    (\"https://leclaireur.fnac.com/selection/cp48395-top-10-les-best-sellers-de-juin-2023/\", \"Juin\"),\n",
    "    (\"https://leclaireur.fnac.com/selection/cp40500-top-10-les-best-sellers-de-juillet-2023/\", \"Juillet\"),\n",
    "    (\"https://leclaireur.fnac.com/selection/cp48936-top-10-les-best-sellers-du-mois-daout-2023/\", \"Août\"),\n",
    "    (\"https://leclaireur.fnac.com/selection/cp49107-top-10-les-best-sellers-du-mois-de-septembre-2023/\", \"Septembre\"),\n",
    "    (\"https://leclaireur.fnac.com/selection/cp49482-top-10-les-best-sellers-du-mois-doctobre-2023/\", \"Octobre\"),\n",
    "    (\"https://leclaireur.fnac.com/selection/cp53758-top-10-les-best-sellers-du-mois-de-novembre-2023/\", \"Novembre\"),\n",
    "    (\"https://leclaireur.fnac.com/selection/cp49831-top-10-les-best-sellers-du-mois-de-decembre-2023/\", \"Décembre\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit notre base de données: changer le nom en df_bestsellers !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping pour le mois de Janvier...\n",
      "Texte brut extrait : 1 – Captive, Tome 2 – Sarah Rivens (BMR)\n",
      "Texte brut extrait : 2 – Le Suppléant – Prince Harry (Fayard)\n",
      "Texte brut extrait : 3 – À tout jamais – Colleen Hoover (Hugo Roman)\n",
      "Texte brut extrait : 4 – Le Silence et la colère – Pierre Lemaitre (Calmann Lévy)\n",
      "Texte brut extrait : 5 – Le Monde sans fin, miracle énergétique et dérive climatique – Christophe Blain, Jean-Marc Jancovici (Dargaud)\n",
      "Texte brut extrait : 6 – Captive, Tome 1 – Sarah Rivens (BMR)\n",
      "Texte brut extrait : 7 – Plus jamais sans moi – Maud Ankaoua (Eyrolles)\n",
      "Texte brut extrait : 8 – Captive, Tome 1.5 : Perfectly Wrong – Sarah Rivens (BMR)\n",
      "Texte brut extrait : 9 – Le Mage du Kremlin – Giuliano Da Empoli (Gallimard)\n",
      "Texte brut extrait : 10 – Kaamelott, Tome 10, Karadoc Et L’Icosaèdre – Steven Dupré, Alexandre Astier (Casterman)\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n",
      "Scraping pour le mois de Février...\n",
      "Texte brut extrait : 1 – À tout jamais – Colleen Hoover (Hugo Roman)\n",
      "Texte brut extrait : 2 – Astérix, Hors collection : L’Empire du milieu – Fabrice Tarrin / Olivier Gay (Albert René)\n",
      "Texte brut extrait : 3 – Captive, Tome 2 – Sarah Rivens (BMR)\n",
      "Texte brut extrait : 4 – Le Monde sans fin, miracle énergétique et dérive climatique – Christophe Blain / Jean-Marc Jancovici (Dargaud)\n",
      "Texte brut extrait : 5 – Connaissance illimitée – Mohamed Boclet (Robert Laffont)\n",
      "Texte brut extrait : 6 – Le Silence et la colère – Pierre Lemaitre (Calmann Lévy)\n",
      "Texte brut extrait : 7 – Le Mage du Kremlin – Giuliano Da Empoli (Gallimard)\n",
      "Texte brut extrait : 8 – La Nuit où les étoiles ses sont éteintes, Tome 1 – Nine Gorman / Marie Alhinho (Albin Michel jeunesse)\n",
      "Texte brut extrait : 9 – Le Suppléant – Prince Harry (Fayard)\n",
      "Texte brut extrait : 10 – Plus jamais sans moi – Maud Ankaoua (Eyrolles)\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n",
      "Scraping pour le mois de Mars...\n",
      "Texte brut extrait : 1 – Blake et Mortimer – Avant Blake et Mortimer T2 : La Flèche ardente – Van Hamme / Cailleaux / Schréder (Blake Et Mortimer)\n",
      "Texte brut extrait : 2 – Captive T1 – Sarah Rivens (BMR)\n",
      "Texte brut extrait : 3 – À tout jamais – Colleen Hoover (Hugo Roman)\n",
      "Texte brut extrait : 4 – Le Monde sans fin, miracle énergétique et dérive climatique – Christophe Blain / Jean-Marc Jancovici (Dargaud)\n",
      "Texte brut extrait : 5 – Les Femmes du bout du monde – Mélissa Da Costa (Calmann Lévy)\n",
      "Texte brut extrait : 6 – Trois vies par semaine – Michel Bussi (Presses de la cité)\n",
      "Texte brut extrait : 7 – Les Éclats – Bret Easton Ellis (Robert Laffont)\n",
      "Texte brut extrait : 8 – Astérix – Hors collection : L’Empire du milieu – Fabrice Tarrin / Olivier Gay (Albert René)\n",
      "Texte brut extrait : 9 – La Nuit où les étoiles ses sont éteintes T1 – Nine Gorman / Marie Alhinho (Albin Michel jeunesse)\n",
      "Texte brut extrait : 10 – L’envol – Aurélie Valognes (Fayard)\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n",
      "Scraping pour le mois de Avril...\n",
      "Texte brut extrait : 1 – Elles, Tome 3 : Plurielle(s) – Kid Toussaint, Aveline Stokart (Le Lombard)\n",
      "Texte brut extrait : 2 – La Mariée portait des bottes jaunes – Katherine Pancol (Albin Michel)\n",
      "Texte brut extrait : 3 – Les Pierres du cauchemar, Tome 2 – Dooms, Sora, Dreamy (Glénat)\n",
      "Texte brut extrait : 4 – Pagny par Florent – Florent Pagny (Fayard)\n",
      "Texte brut extrait : 5 – Le Défi de Jérusalem – Éric-Emmanuel Schmitt (Albin Michel)\n",
      "Texte brut extrait : 6 – Captive, Tome 1 –Sarah Rivens (BMR)\n",
      "Texte brut extrait : 7 – Un œil dans la nuit – Bernard Minier (XO)\n",
      "Texte brut extrait : 8 – Conte de fées – Stephen King (Albin Michel)\n",
      "Texte brut extrait : 9 – À tout jamais – Colleen Hoover (Hugo Roman)\n",
      "Texte brut extrait : 10 – Mortelle Adèle : Le Journal des bizarres – Mr Tan, Diane Le Feyer (Mr Tan & co)\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n",
      "Scraping pour le mois de Mai...\n",
      "Texte brut extrait : 1 – Les Enquêtes d’Adamsberg : Sur la dalle – Fred Vargas (Flammarion)\n",
      "Texte brut extrait : 2 – Les Cahiers d’Esther, Tome 8 : Histoires de mes 17 ans – Riad Sattouf (Allary)\n",
      "Texte brut extrait : 3 – Une belle vie – Virginie Grimaldi (Flammarion)\n",
      "Texte brut extrait : 4 – La Faille – Franck Thilliez (Fleuve)\n",
      "Texte brut extrait : 5 – Pagny par Florent – Florent Pagny (Fayard)\n",
      "Texte brut extrait : 6 – Les sept sœurs : Atlas, l’histoire de Pa Salt – Lucinda Riley (Charleston)\n",
      "Texte brut extrait : 7 – La Mariée portait des bottes jaunes – Katherine Pancol (Albin Michel)\n",
      "Texte brut extrait : 8 – Rouge Karma – Jean-Christophe Grangé (Albin Michel)\n",
      "Texte brut extrait : 9 – Le Culte – Camilla Läckberg, Henrik Fexeus (Actes sud)\n",
      "Texte brut extrait : 10 – À tout jamais – Colleen Hoover (Hugo Roman)\n",
      "Texte brut extrait : Retrouvez tout l’actualité Livre sur Fnac.com\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n",
      "Scraping pour le mois de Juin...\n",
      "Texte brut extrait : 1 – Les Enquêtes d’Adamsberg : Sur la dalle – Fred Vargas (Flammarion)\n",
      "Texte brut extrait : 2 – Les Cahiers d’Esther, Tome8 : Histoires de mes 17 ans – Riad Sattouf (Allary)\n",
      "Texte brut extrait : 3 – Bleak – 3 histoires d’horreur, Volume 2 – Squeezie (Link Digital)\n",
      "Texte brut extrait : 4 – Une belle vie – Virginie Grimaldi (Flammarion)\n",
      "Texte brut extrait : 5 – À tout jamais – Colleen Hoover (Hugo Roman)\n",
      "Texte brut extrait : 6 – Mortelle Adèle, Tome 4 : V.I.B – Mr Tan, Diane Le Feyer (Mr Tan & co)\n",
      "Texte brut extrait : 7 – La Faille – Franck Thilliez (Fleuve)\n",
      "Texte brut extrait : 8 – Elles, Tome 3 : Plurielle(s) – Kid Toussaint, Aveline Stokart (Le Lombard)\n",
      "Texte brut extrait : 9 – The Devil’s Sons, Tome 2 – Chloé Wallerand (Plumes du web)\n",
      "Texte brut extrait : 10 – Captive, Tome 2 – Sarah Rivens (Hlab)\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n",
      "Scraping pour le mois de Juillet...\n",
      "Texte brut extrait : 1 – Les Enquêtes d’Adamsberg : Sur la dalle – Fred Vargas (Flammarion)\n",
      "Texte brut extrait : 2 – Fallen Angel – Camille Creati  (Hlab)\n",
      "Texte brut extrait : 3 – Captive, Tome 1 – Sarah Rivens (Hlab)\n",
      "Texte brut extrait : 4 – Son odeur après la pluie – Cédric Sapin-Dufour (Stock)\n",
      "Texte brut extrait : 5 – À tout jamais – Colleen Hoover (Hugo Roman)\n",
      "Texte brut extrait : 6 – Une belle vie – Virginie Grimaldi (Flammarion)\n",
      "Texte brut extrait : 7 – À Contre-Sens, Tome 1 et Tome 2 – Mercedes Ron (Hachette Romans)\n",
      "Texte brut extrait : 8 – La Faille – Franck Thilliez (Fleuve)\n",
      "Texte brut extrait : 9 – Beyond The Story, 10 ans de souvenirs de BTS – Bangtang Boys (Seuil)\n",
      "Texte brut extrait : 10 – Bleak, 3 histoires d’horreur Volume 2 – Squeezie (Link Digital)\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n",
      "Scraping pour le mois de Août...\n",
      "Texte brut extrait : 1 – Psychopompe – Amélie Nothomb (Albin Michel)\n",
      "Texte brut extrait : 2 – La prochaine fois que tu mordras la poussière – Panayotis Pascot (Stock)\n",
      "Texte brut extrait : 3 – Le Jeu des tricheurs – Anita Rigins (Hugo Romans)\n",
      "Texte brut extrait : 4 – Son odeur après la pluie – Cédric Sapin-Defour (Stock)\n",
      "Texte brut extrait : 5 – Le Monde sans fin, miracle énergétique et dérive climatique – Christophe Blain, Jean-Marc Jancovici (Dargaud)\n",
      "Texte brut extrait : 6 – Icebreaker – Hannah Grace (Hlab)\n",
      "Texte brut extrait : 7 – Mon budget sur pilote automatique, Le Carnet – Maeva Derby (Alisio)\n",
      "Texte brut extrait : 8 – Captive, Tome 1 – Sarah Rivens (Hlab)\n",
      "Texte brut extrait : 9 – Fallen Angel – Camille Creati (Hlab)\n",
      "Texte brut extrait : 10 – À tout jamais – Colleen Hoover (Hugo Roman)\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n",
      "Scraping pour le mois de Septembre...\n",
      "Texte brut extrait : 1 – Les 4 Saisons, Tome 1 : Un automne pour te pardonner – Morgane Moncomble (Hugo Roman)\n",
      "Texte brut extrait : 2 – La prochaine fois que tu mordras la poussière – Panayotis Pascot (Stock)\n",
      "Texte brut extrait : 3 – L’Homme des Mille Détours – Agnès Martin-Lugand (Michel Lafon)\n",
      "Texte brut extrait : 4 – Solo Leveling, Tome 11 – Chugong / Dubu (Kbooks)\n",
      "Texte brut extrait : 5 – Le Nom de la rose, Tome 1 – Milo Manara / Umberto Eco (Glénat)\n",
      "Texte brut extrait : 6 – Adieu Birkenau – Ginette Kolinka (Albin Michel)\n",
      "Texte brut extrait : 7 – Veiller sur elle – Jean-Baptiste Andrea (L’Iconoclaste)\n",
      "Texte brut extrait : 8 – Bellatrix, Tome 1 – Léo (Dargaud)\n",
      "Texte brut extrait : 9 – Happy Hours – Anna RVR  (Hachette Pratique)\n",
      "Texte brut extrait : 10 – Psychopompe – Amélie Nothomb (Albin Michel)\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n",
      "Scraping pour le mois de Octobre...\n",
      "Texte brut extrait : 1 – Astérix, Tome 40 : L’Iris blanc – Didier Conrad, Fabcaro (Albert René)\n",
      "Texte brut extrait : 2 – Blake & Mortimer : L’Art de la guerre – Floc’h, Jean-Luc Fromental, José-Luis Bocquet (Blake et Mortimer)\n",
      "Texte brut extrait : 3 – Le Voyage de Shuna – Hayao Miyazaki (Sarbacane)\n",
      "Texte brut extrait : 4 – Blacksad, Tome 7 : Alors, tout tombe (seconde partie) – Juan Diaz Canalès, Juanjo Guarnido (Dargaud)\n",
      "Texte brut extrait : 5 – Mortelle Adèle, Tome 20 : J’apocalypse grave ! – Mr Tan, Diane Le Feyer (Mr Tan & co)\n",
      "Texte brut extrait : 6 – Twisted, Tome 1 : Twisted Love – Ana Huang (Hugo Roman)\n",
      "Texte brut extrait : 7 – Les 4 Saisons, Tome 1 : Un automne pour te pardonner – Morgane Moncomble (Hugo Roman)\n",
      "Texte brut extrait : 8 – La prochaine fois que tu mordras la poussière – Panayotis Pascot (Stock)\n",
      "Texte brut extrait : 9 – La Mort n’existe pas – Stéphane Allix (Harpercollins)\n",
      "Texte brut extrait : 10 – La Femme en moi – Britney Spears (JC Lattès)\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n",
      "Scraping pour le mois de Novembre...\n",
      "Texte brut extrait : 1 – Gaston Lagaffe, Tome 22 : Le retour de Lagaffe – Delaf, Franquin (Dupuis)\n",
      "Texte brut extrait : 2 – Astérix Tome 40 : L’Iris blanc – Didier Conrad, Fabcaro (Albert René)\n",
      "Texte brut extrait : 3 – Veiller sur elle – Jean-Baptiste Andrea (L’Iconoclaste)\n",
      "Texte brut extrait : 4 – Histoire de Jérusalem – Vincent Lemire, Christophe Gaultier (Les Arènes)\n",
      "Texte brut extrait : 5 – Triste tigre – Neige Sinno (P.O.L)\n",
      "Texte brut extrait : 6 – Le Voyage de Shuna – Hayao Miyazaki (Sarbacane)\n",
      "Texte brut extrait : 7 – Largo Winch, Tome 24 : Le Centile d’or – Giacometti, Francq (Dupuis)\n",
      "Texte brut extrait : 8 – Blacksad, Tome 7 : Alors, tout tombe (seconde partie) – Juan Diaz Canalès, Juanjo Guarnido (Dargaud)\n",
      "Texte brut extrait : 9 – Lou, Tome 2 : Sonata  – Julien Neel, Carole Neel  (Glénat)\n",
      "Texte brut extrait : 10 – Ma vie sans gravité – Thomas Pesquet (Flammarion)\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n",
      "Scraping pour le mois de Décembre...\n",
      "Texte brut extrait : 1 – Astérix, Tome 40 : L’Iris blanc – Didier Conrad / Fabcaro (Albert René)\n",
      "Texte brut extrait : 2 – Gaston Lagaffe, Tome 22 : Le retour de Lagaffe – Delaf / Franquin (Dupuis)\n",
      "Texte brut extrait : 3 – Veiller sur elle – Jean-Baptiste Andrea (L’Iconoclaste)\n",
      "Texte brut extrait : 4 – Histoire de Jérusalem – Vincent Lemire / Christophe Gaultier (Les Arènes)\n",
      "Texte brut extrait : 5 – Son odeur après la pluie – Cédric Sapin-Defour (Stock)\n",
      "Texte brut extrait : 6 – Mortelle Adèle et les reliques du chat lune, Tome 4 – Mr Tan / Olivier Bonnassies (Mr Tan & co)\n",
      "Texte brut extrait : 7 – Triste tigre – Neige Sinno (P.O.L)\n",
      "Texte brut extrait : 8 – Twisted, Tome 1 : Twisted Love – Ana Huang (Hugo Roman)\n",
      "Texte brut extrait : 9 – Lou ! Sonata, Tome 2 – Julien Neel / Carole Neel  (Glénat)\n",
      "Texte brut extrait : 10 – La prochaine fois que tu mordras la poussière – Panayotis Pascot (Stock)\n",
      "Texte brut extrait : Partagez vos coups de cœur sur le Forum des Lecteurs\n"
     ]
    }
   ],
   "source": [
    "# On initialise la liste pour toutes les données\n",
    "top_data_2023 = []\n",
    "\n",
    "# On scrape chaque URL\n",
    "for url, month in urls_months:\n",
    "    print(f\"Scraping pour le mois de {month}...\")\n",
    "    month_data = scrape_titles_and_authors(url, month)\n",
    "    top_data_2023.extend(month_data)\n",
    "\n",
    "# Conversion des données en DataFrame pandas\n",
    "df_top_books_2023 = pd.DataFrame(top_data_2023, columns=[\"Mois\", \"Classement\", \"Titre\", \"Auteur\", \"Co_auteur1\", \"Co_auteur2\"])\n",
    "\n",
    "# Création de la variable indicatrice \"top_fnac_1\" (tous les livres ont un classement)\n",
    "df_top_books_2023['top_fnac_1'] = 1\n",
    "\n",
    "# Comptage des occurrences des livres pour créer \"top_fnac_2_plus\"\n",
    "counts = df_top_books_2023['Titre'].value_counts()\n",
    "df_top_books_2023['top_fnac_2_plus'] = df_top_books_2023['Titre'].apply(lambda x: 1 if counts[x] > 1 else 0)\n",
    "\n",
    "# Suppression des colonnes \"Mois\" et \"Classement\", et suppression des doublons\n",
    "df_top_books_2023 = df_top_books_2023.drop(columns=[\"Mois\", \"Classement\"]).drop_duplicates(subset=['Titre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche le dataframe pour vérifier qu'il n'y a pas de problèmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Titre            Auteur  \\\n",
      "0                                      Captive, Tome 2      Sarah Rivens   \n",
      "1                                         Le Suppléant      Prince Harry   \n",
      "2                                        À tout jamais    Colleen Hoover   \n",
      "3                              Le Silence et la colère   Pierre Lemaitre   \n",
      "4    Le Monde sans fin, miracle énergétique et déri...  Christophe Blain   \n",
      "..                                                 ...               ...   \n",
      "105             Largo Winch, Tome 24 : Le Centile d’or        Giacometti   \n",
      "107                               Lou, Tome 2 : Sonata       Julien Neel   \n",
      "108                                Ma vie sans gravité    Thomas Pesquet   \n",
      "114  Mortelle Adèle et les reliques du chat lune, T...            Mr Tan   \n",
      "117                               Lou ! Sonata, Tome 2       Julien Neel   \n",
      "\n",
      "              Co_auteur1 Co_auteur2  top_fnac_1  top_fnac_2_plus  \n",
      "0                   None       None           1                1  \n",
      "1                   None       None           1                1  \n",
      "2                   None       None           1                1  \n",
      "3                   None       None           1                1  \n",
      "4    Jean-Marc Jancovici       None           1                1  \n",
      "..                   ...        ...         ...              ...  \n",
      "105               Francq       None           1                0  \n",
      "107          Carole Neel       None           1                0  \n",
      "108                 None       None           1                0  \n",
      "114   Olivier Bonnassies       None           1                0  \n",
      "117          Carole Neel       None           1                0  \n",
      "\n",
      "[76 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_top_books_2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme il y a trop de lignes pour afficher le dataframe, on vérifie nos données en faisant un dossier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_books_2023.to_csv(\"best_sellers_fnac_2023_cleaned.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On corrige les quelques incohérences à la main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_books_2023.loc[df_top_books_2023['Auteur'] == \"Astérix,Hors collection : L’Empire du milieu – Fabrice Tarrin\",['Titre', 'Auteur']] = ['Astérix, Hors collection : L’Empire du milieu', \"Fabrice Tarrin\"]\n",
    "df_top_books_2023.loc[df_top_books_2023['Auteur'] == \"Blake et Mortimer,Avant Blake et Mortimer T2 : La Flèche ardente – Van Hamme\",['Titre', 'Auteur']] = ['Blake et Mortimer,Avant Blake et Mortimer T2 : La Flèche ardente', \"– Van Hamme\"]\n",
    "df_top_books_2023.loc[df_top_books_2023['Titre'] == \"Bleak\",['Titre', 'Auteur', 'Co_auteur1']] = ['Bleak,3 histoires d’horreur,Volume 2', \"Squeezie\", None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, pour harmoniser cette base et rendre plus simple le merge, nous avons voulu mettre tous les auteurs dans la colonne Auteur et enlever les colonnes de co-auteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_author(row):\n",
    "    if row['Co_auteur1'] is not None and row['Co_auteur2'] is not None:\n",
    "        author= row['Auteur'] + ', '+ row['Co_auteur1'] + ', '+ row['Co_auteur2']\n",
    "    elif row['Co_auteur1'] is not None and row['Co_auteur2'] is None:\n",
    "        author= row['Auteur'] + ', '+ row['Co_auteur1']\n",
    "    else:\n",
    "        author = row['Auteur']\n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_books_2023['Auteur'] = df_top_books_2023.apply(column_author, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie que cela a bien marché"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>Co_auteur1</th>\n",
       "      <th>Co_auteur2</th>\n",
       "      <th>top_fnac_1</th>\n",
       "      <th>top_fnac_2_plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Captive, Tome 2</td>\n",
       "      <td>Sarah Rivens</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le Suppléant</td>\n",
       "      <td>Prince Harry</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>À tout jamais</td>\n",
       "      <td>Colleen Hoover</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Silence et la colère</td>\n",
       "      <td>Pierre Lemaitre</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le Monde sans fin, miracle énergétique et déri...</td>\n",
       "      <td>Christophe Blain, Jean-Marc Jancovici</td>\n",
       "      <td>Jean-Marc Jancovici</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Captive, Tome 1</td>\n",
       "      <td>Sarah Rivens</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plus jamais sans moi</td>\n",
       "      <td>Maud Ankaoua</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Captive, Tome 1.5 : Perfectly Wrong</td>\n",
       "      <td>Sarah Rivens</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Le Mage du Kremlin</td>\n",
       "      <td>Giuliano Da Empoli</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kaamelott, Tome 10, Karadoc Et L’Icosaèdre</td>\n",
       "      <td>Steven Dupré, Alexandre Astier</td>\n",
       "      <td>Alexandre Astier</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Titre  \\\n",
       "0                                    Captive, Tome 2   \n",
       "1                                       Le Suppléant   \n",
       "2                                      À tout jamais   \n",
       "3                            Le Silence et la colère   \n",
       "4  Le Monde sans fin, miracle énergétique et déri...   \n",
       "5                                    Captive, Tome 1   \n",
       "6                               Plus jamais sans moi   \n",
       "7                Captive, Tome 1.5 : Perfectly Wrong   \n",
       "8                                 Le Mage du Kremlin   \n",
       "9         Kaamelott, Tome 10, Karadoc Et L’Icosaèdre   \n",
       "\n",
       "                                  Auteur           Co_auteur1 Co_auteur2  \\\n",
       "0                           Sarah Rivens                 None       None   \n",
       "1                           Prince Harry                 None       None   \n",
       "2                         Colleen Hoover                 None       None   \n",
       "3                        Pierre Lemaitre                 None       None   \n",
       "4  Christophe Blain, Jean-Marc Jancovici  Jean-Marc Jancovici       None   \n",
       "5                           Sarah Rivens                 None       None   \n",
       "6                           Maud Ankaoua                 None       None   \n",
       "7                           Sarah Rivens                 None       None   \n",
       "8                     Giuliano Da Empoli                 None       None   \n",
       "9         Steven Dupré, Alexandre Astier     Alexandre Astier       None   \n",
       "\n",
       "   top_fnac_1  top_fnac_2_plus  \n",
       "0           1                1  \n",
       "1           1                1  \n",
       "2           1                1  \n",
       "3           1                1  \n",
       "4           1                1  \n",
       "5           1                1  \n",
       "6           1                1  \n",
       "7           1                0  \n",
       "8           1                1  \n",
       "9           1                0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_books_2023.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut donc maintenant enlever les colonnes indésirables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_books_2023 = df_top_books_2023.drop(columns=['Co_auteur1', 'Co_auteur2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>top_fnac_1</th>\n",
       "      <th>top_fnac_2_plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Captive, Tome 2</td>\n",
       "      <td>Sarah Rivens</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le Suppléant</td>\n",
       "      <td>Prince Harry</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>À tout jamais</td>\n",
       "      <td>Colleen Hoover</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Silence et la colère</td>\n",
       "      <td>Pierre Lemaitre</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le Monde sans fin, miracle énergétique et déri...</td>\n",
       "      <td>Christophe Blain, Jean-Marc Jancovici</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Titre  \\\n",
       "0                                    Captive, Tome 2   \n",
       "1                                       Le Suppléant   \n",
       "2                                      À tout jamais   \n",
       "3                            Le Silence et la colère   \n",
       "4  Le Monde sans fin, miracle énergétique et déri...   \n",
       "\n",
       "                                  Auteur  top_fnac_1  top_fnac_2_plus  \n",
       "0                           Sarah Rivens           1                1  \n",
       "1                           Prince Harry           1                1  \n",
       "2                         Colleen Hoover           1                1  \n",
       "3                        Pierre Lemaitre           1                1  \n",
       "4  Christophe Blain, Jean-Marc Jancovici           1                1  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_books_2023.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On modifie le fichier CSV pour merge plus tard les bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_books_2023.to_csv(\"best_sellers_fnac_2023_cleaned.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie 2: Récupérer des données sur des systèmes permettant de juger de la qualité des livres.\n",
    "Le but est d'essayer de comprendre s'il y a une corrélation entre les livres lus et les livres jugés de qualité, mais aussi entre les livres jugés de qualité et les livres présentés dans des vidéos Youtube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, on s'intéresse aux livres sortis en 2023 les mieux notés sur la plateforme Livraddict. On en importe les titres et les auteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la page à scrapper\n",
    "livraddict_top_2023 = \"https://www.livraddict.com/prix-livraddict/2024/\"\n",
    "\n",
    "# Requête HTTP vers la page\n",
    "response = requests.get(livraddict_top_2023)\n",
    "response.encoding = 'utf-8'\n",
    "\n",
    "# On vérfie que le site autorise le scraping et on scrap si oui\n",
    "if response.status_code == 200:  \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Liste pour stocker les données extraites\n",
    "    livraddict_data = []\n",
    "\n",
    "    # On parcourt toutes les catégories\n",
    "    categories = soup.find_all('div', class_='categorie_prix portlet light')\n",
    "    for category in categories:\n",
    "        # On extrait le nom de la catégorie et supprime \"catégorie\" devant si présent\n",
    "        category_name = category.find('h2').text.strip()\n",
    "        if \"catégorie\" in category_name.lower():\n",
    "            category_name = category_name.lower().replace(\"catégorie\", \"\").strip().capitalize()\n",
    "\n",
    "        # On parcourt les livres de la catégorie\n",
    "        books = category.find_all('div', style=lambda x: x and \"margin-bottom:10px\" in x)\n",
    "        for book in books:\n",
    "            # On extrait le titre du livre\n",
    "            title_tag = book.find('h3').find('a')\n",
    "            title = title_tag.find('strong').text.strip() if title_tag else None\n",
    "\n",
    "            # On extrait l'auteur du livre\n",
    "            author = title_tag.contents[-1].strip() if title_tag else None\n",
    "\n",
    "            # On ajoute les informations à la liste créée\n",
    "            if title and author:\n",
    "                livraddict_data.append([category_name, title, author])\n",
    "\n",
    "    # On convertit les données en DataFrame\n",
    "    df_livraddict_data = pd.DataFrame(livraddict_data, columns=['Catégorie', 'Titre', 'Auteur'])\n",
    "\n",
    "    # On ajoute une colonne indicatrice \"top_livraddict\"\n",
    "    df_livraddict_data['top_livraddict'] = 1\n",
    "else:\n",
    "    print(\"Erreur {response.status_code} lors de la requête.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde la base pour s'assurer qu'il n'y ait pas d'incohérence et pour se familiariser avec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Catégorie</th>\n",
       "      <th>Titre</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>top_livraddict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Young adult</td>\n",
       "      <td>Engélion, tome 1 : Illuminer les Cieux</td>\n",
       "      <td>Justine Tiphagne</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Young adult</td>\n",
       "      <td>Tant que fleuriront les citronniers (As Long a...</td>\n",
       "      <td>Zoulfa Katouh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Young adult</td>\n",
       "      <td>L'effet Boule de neige</td>\n",
       "      <td>Clara Héraut</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Young adult</td>\n",
       "      <td>Écarlate sous la cendre, tome 1</td>\n",
       "      <td>Élisabeth Koshava</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Young adult</td>\n",
       "      <td>Le sirénien</td>\n",
       "      <td>Capucine Sergent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jeunesse</td>\n",
       "      <td>Wonka</td>\n",
       "      <td>Sibéal Pounder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jeunesse</td>\n",
       "      <td>L'étoile du soir</td>\n",
       "      <td>Siècle Vaëlban</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jeunesse</td>\n",
       "      <td>Les clans du ciel, tome 1 : La quête d'Ellie (...</td>\n",
       "      <td>Jessica Khoury</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jeunesse</td>\n",
       "      <td>Crook Haven, tome 1 : L'école des voleurs  (Cr...</td>\n",
       "      <td>J. J. Arcanjo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jeunesse</td>\n",
       "      <td>Sentinelles du Royaume Sauvage, tome 1</td>\n",
       "      <td>Alexandra Ott</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Catégorie                                              Titre  \\\n",
       "0  Young adult             Engélion, tome 1 : Illuminer les Cieux   \n",
       "1  Young adult  Tant que fleuriront les citronniers (As Long a...   \n",
       "2  Young adult                             L'effet Boule de neige   \n",
       "3  Young adult                    Écarlate sous la cendre, tome 1   \n",
       "4  Young adult                                        Le sirénien   \n",
       "5     Jeunesse                                              Wonka   \n",
       "6     Jeunesse                                   L'étoile du soir   \n",
       "7     Jeunesse  Les clans du ciel, tome 1 : La quête d'Ellie (...   \n",
       "8     Jeunesse  Crook Haven, tome 1 : L'école des voleurs  (Cr...   \n",
       "9     Jeunesse             Sentinelles du Royaume Sauvage, tome 1   \n",
       "\n",
       "              Auteur  top_livraddict  \n",
       "0   Justine Tiphagne               1  \n",
       "1      Zoulfa Katouh               1  \n",
       "2       Clara Héraut               1  \n",
       "3  Élisabeth Koshava               1  \n",
       "4   Capucine Sergent               1  \n",
       "5     Sibéal Pounder               1  \n",
       "6     Siècle Vaëlban               1  \n",
       "7     Jessica Khoury               1  \n",
       "8      J. J. Arcanjo               1  \n",
       "9      Alexandra Ott               1  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_livraddict_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_livraddict_data.to_csv('livraddict_prix_2024.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération de tous les prix littéraires français connus de Wikipédia entre 2019 et 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un dataframe vide pour ensuite entrer les donner scrappées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Année, Prix, Auteur, Titre]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "colonnes = ['Année', 'Prix', 'Auteur', 'Titre']\n",
    "\n",
    "# Créer un DataFrame vide avec ces colonnes\n",
    "df_wikipedia = pd.DataFrame(columns=colonnes)\n",
    "\n",
    "print(df_wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapping sur wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wikipedia_page_france(year):\n",
    "    global df_wikipedia\n",
    "    url = f\"https://fr.wikipedia.org/wiki/Prix_litt%C3%A9raires_{year}\"\n",
    "    response = requests.get(url)\n",
    "    response.encoding = \"utf-8\"  # On garantit le bon encodage\n",
    "\n",
    "    if response.status_code == 200:  # On vérifie si la requête est un succès\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # On recherche la section France\n",
    "        france_section = soup.find('h2', string=\"France\")\n",
    "        if france_section:\n",
    "            # La liste <ul> qui suit contient les prix pour la France\n",
    "            france_list = france_section.find_next('ul')\n",
    "\n",
    "            if france_list:\n",
    "                # On recherche tous les <li> dans la liste\n",
    "                prizes = france_list.find_all('li')\n",
    "\n",
    "                # On extrait les données\n",
    "                for prize in prizes:\n",
    "                    # Nom du prix\n",
    "                    prize_name = prize.find('a')\n",
    "                    prize_name = prize_name.text.strip() if prize_name else None\n",
    "\n",
    "                    # Auteur\n",
    "                    author = prize.find_all('a')\n",
    "                    author = author[1].text.strip() if len(author) > 1 else None\n",
    "\n",
    "                    # Titre\n",
    "                    title = prize.find('i')\n",
    "                    title = title.text.strip() if title else None\n",
    "\n",
    "                    # On ajoute les résultats si les données sont complètes\n",
    "                    if prize_name and author and title:\n",
    "                        new_row = {'Année': year, 'Prix': prize_name, 'Auteur': author, 'Titre': title}\n",
    "                        df_wikipedia = pd.concat([df_wikipedia, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Section 'France' non trouvée pour l'année {year}\")\n",
    "    else:\n",
    "        print(f\"Erreur lors du scraping de l'année {year}: Status code {response.status_code}\")\n",
    "\n",
    "    return df_wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2019, 2024):\n",
    "    scrape_wikipedia_page_france(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand on regarde les données, on voit bien qu'il y a de gros problèmes. En regardant le fichier csv, c'est d'autant plus flagrant. Nous avons identifiés plusieurs types de problèmes, que nous avons étudié puis corrigé soit manuellement quand il ne concernait que quelques lignes, soit automatiquement, en scrappant sur un autre site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Année</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina</td>\n",
       "      <td>Par les routes</td>\n",
       "      <td>Par les routes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina étranger</td>\n",
       "      <td>Ordesa</td>\n",
       "      <td>Ordesa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina essai</td>\n",
       "      <td>Emmanuelle Lambert</td>\n",
       "      <td>Giono furioso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina des lycéens</td>\n",
       "      <td>La Chaleur</td>\n",
       "      <td>La Chaleur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Goncourt</td>\n",
       "      <td>Tous les hommes n'habitent pas le monde de la ...</td>\n",
       "      <td>Tous les hommes n'habitent pas le monde de la ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Année                     Prix  \\\n",
       "0  2019              Prix Femina   \n",
       "1  2019     Prix Femina étranger   \n",
       "2  2019        Prix Femina essai   \n",
       "3  2019  Prix Femina des lycéens   \n",
       "4  2019            Prix Goncourt   \n",
       "\n",
       "                                              Auteur  \\\n",
       "0                                     Par les routes   \n",
       "1                                             Ordesa   \n",
       "2                                 Emmanuelle Lambert   \n",
       "3                                         La Chaleur   \n",
       "4  Tous les hommes n'habitent pas le monde de la ...   \n",
       "\n",
       "                                               Titre  \n",
       "0                                     Par les routes  \n",
       "1                                             Ordesa  \n",
       "2                                      Giono furioso  \n",
       "3                                         La Chaleur  \n",
       "4  Tous les hommes n'habitent pas le monde de la ...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wikipedia.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia.to_csv(\"prix_litteraires.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier type d'incohérence ( aussi le plus important): il y a eu une erreur dans le scrapping de nombreux ouvrages sur Wikipédia qui a fait qu'on a deux fois le Titre des livres au lieu d'en avoir l'auteur ou les auteurs. Ce problème concerne 81 ligne, ce qui est un nombre considérable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Année                                         Prix  \\\n",
      "0    2019                                  Prix Femina   \n",
      "1    2019                         Prix Femina étranger   \n",
      "3    2019                      Prix Femina des lycéens   \n",
      "4    2019                                Prix Goncourt   \n",
      "5    2019               Prix Goncourt du premier roman   \n",
      "..    ...                                          ...   \n",
      "189  2022  Grand prix du roman de l'Académie française   \n",
      "218  2022                          Grand prix RTL-Lire   \n",
      "223  2022                    Grand Prix Roman de l'été   \n",
      "290  2023                    Grand Prix Roman de l'été   \n",
      "292  2023                                   Ada Palmer   \n",
      "\n",
      "                                                Auteur  \\\n",
      "0                                       Par les routes   \n",
      "1                                               Ordesa   \n",
      "3                                           La Chaleur   \n",
      "4    Tous les hommes n'habitent pas le monde de la ...   \n",
      "5                                          Court vêtue   \n",
      "..                                                 ...   \n",
      "189                                 Le Mage du Kremlin   \n",
      "218                                                555   \n",
      "223                                     Femme Actuelle   \n",
      "290                                     Femme Actuelle   \n",
      "292                                       Terra Ignota   \n",
      "\n",
      "                                                 Titre  \n",
      "0                                       Par les routes  \n",
      "1                                               Ordesa  \n",
      "3                                           La Chaleur  \n",
      "4    Tous les hommes n'habitent pas le monde de la ...  \n",
      "5                                          Court vêtue  \n",
      "..                                                 ...  \n",
      "189                                 Le Mage du Kremlin  \n",
      "218                                                555  \n",
      "223                                     Femme Actuelle  \n",
      "290                                     Femme Actuelle  \n",
      "292                                       Terra Ignota  \n",
      "\n",
      "[81 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_double = df_wikipedia[df_wikipedia['Auteur']==df_wikipedia['Titre']]\n",
    "print(df_double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le deuxième grand problème que nous avons rencontré est le remplacement des noms d'auteurs par des chiffres entre crochets pour 13 lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Année                                  Prix Auteur  \\\n",
      "104  2020              Prix littéraire du Monde    [4]   \n",
      "150  2021                   Prix Première Plume    [3]   \n",
      "157  2021  Prix Eugène-Dabit du roman populiste    [5]   \n",
      "180  2022        Prix Goncourt de la biographie   [10]   \n",
      "209  2022                           Anne Berest   [33]   \n",
      "210  2022      Prix littéraire ENS Paris-Saclay   [34]   \n",
      "214  2022             Prix du Quai des Orfèvres   [38]   \n",
      "217  2022  Prix Eugène-Dabit du roman populiste   [41]   \n",
      "222  2022      Grand prix des lectrices de Elle   [45]   \n",
      "225  2022       Grand Prix de Poésie de la SGDL   [46]   \n",
      "227  2022                           Prix Wepler   [47]   \n",
      "247  2023        Prix Goncourt de la biographie   [45]   \n",
      "297  2023   Prix littéraire de la Ville de Caen   [70]   \n",
      "\n",
      "                              Titre  \n",
      "104                           Monde  \n",
      "150  Avant que le monde ne se ferme  \n",
      "157              Des gens comme eux  \n",
      "180           Léopold Sédar Senghor  \n",
      "209                La Carte postale  \n",
      "210                      Le Passeur  \n",
      "214                   La Muse rouge  \n",
      "217   Les Garçons de la cité-jardin  \n",
      "222                La Carte postale  \n",
      "225          Réacteur 3 [Fukushima]  \n",
      "227            Les Enfants endormis  \n",
      "247                   Georges Perec  \n",
      "297   Mourir avant que d'apparaître  \n"
     ]
    }
   ],
   "source": [
    "df_ch = df_wikipedia[df_wikipedia['Auteur'].str.contains(r'^\\[\\d+\\]$')]\n",
    "print(df_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a parfois eu des incohérences dans les lignes correspondant à des prix en particulier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cas 1: le prix François Mauriac. Le nom complet du prix est \"Prix François Mauriac de l'Académie française\". La deuxième partie de son nom a remplacé tous les noms d'auteurs sensés être récoltés lors du scrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Année                   Prix              Auteur  \\\n",
      "53   2019  Prix François-Mauriac  Académie française   \n",
      "90   2020  Prix François-Mauriac  Académie française   \n",
      "199  2022  Prix François-Mauriac  Académie française   \n",
      "267  2023  Prix François-Mauriac  Académie française   \n",
      "\n",
      "                                  Titre  \n",
      "53   Là-bas, août est un mois d'automne  \n",
      "90               Un automne de Flaubert  \n",
      "199                                Zita  \n",
      "267   À l’abri des hommes et des choses  \n"
     ]
    }
   ],
   "source": [
    "df_mauriac = df_wikipedia[df_wikipedia['Prix']=='Prix François-Mauriac']\n",
    "print(df_mauriac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas 2: Le prix Telerama. Tous les noms de livre ont été remplacés par la chaîne de caractère \"Télérama\". Les noms d'auteurs ne sont pour autant pas tout le temps juste puisqu'il y a parfois dans la colonne \"Auteur\" le titre apparent du livre au lieu d'y avoir le nom de la personne l'ayant écrit. Du fait du manque d'uniformité de ces incohérences, nous avons décidé de les corriger manuellement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Année                          Prix           Auteur     Titre\n",
      "28   2019  Prix France Culture-Télérama        La Maison  Télérama\n",
      "97   2020  Prix France Culture-Télérama         Chavirer  Télérama\n",
      "208  2022  Prix France Culture-Télérama   Kaouther Adimi  Télérama\n",
      "276  2023  Prix France Culture-Télérama  Salma El Moumni  Télérama\n"
     ]
    }
   ],
   "source": [
    "df_telerama = df_wikipedia[df_wikipedia['Prix']=='Prix France Culture-Télérama']\n",
    "print(df_telerama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correction manuelle: nous avons aussi rajouté une ligne pusiqu'il manquait l'année 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia.loc[(df_wikipedia[\"Prix\"] == \"Prix France Culture-Télérama\") & (df_wikipedia[\"Année\"] == 2019), [\"Auteur\", \"Titre\"]] = [\"Emma Becker\", \"La Maison\"]\n",
    "df_wikipedia.loc[(df_wikipedia[\"Prix\"] == \"Prix France Culture-Télérama\") & (df_wikipedia[\"Année\"] == 2020), [\"Auteur\", \"Titre\"]] = [\"Lola Lafon\", \"Chavirer\"]\n",
    "df_wikipedia.loc[(df_wikipedia[\"Prix\"] == \"Prix France Culture-Télérama\") & (df_wikipedia[\"Année\"] == 2022), \"Titre\"] = \"Au vent mauvais\"\n",
    "df_wikipedia.loc[(df_wikipedia[\"Prix\"] == \"Prix France Culture-Télérama\") & (df_wikipedia[\"Année\"] == 2023), \"Titre\"] = \"Adieu Tanger\"\n",
    "nouvelle_ligne = pd.DataFrame({'Année': [2021], 'Prix': [\"Prix France Culture-Télérama\"], 'Auteur':['Mathieu Palain'], 'Titre':[\"Ne t'arrête pas de courir \"]})\n",
    "df_wikipedia = pd.concat([df_wikipedia, nouvelle_ligne], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cas 3: le prix Maya. Ici, ce sont les noms d'auteur qui ont été remplacés par \"animaliste\", un peu comme pour le prix François Mauriac. Il est donc possible d'automatiser le traitement de cette incohérence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Année       Prix      Auteur                       Titre\n",
      "61   2019  Prix Maya  animaliste  Les Paupières des poissons\n",
      "124  2020  Prix Maya  animaliste            Insolente Veggie\n"
     ]
    }
   ],
   "source": [
    "df_maya = df_wikipedia[df_wikipedia['Prix']=='Prix Maya']\n",
    "print(df_maya)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cas 4: le prix Femme Actuelle. Ici, il n'y a ni titre ni auteur: les deux colonnes ont été remplacé par \"Femme actuelle\". De ce fait, il sera ici aussi nécessaire de corriger manuellement les erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Année                       Prix          Auteur           Titre\n",
      "46   2019  Grand Prix Roman de l'été  Femme Actuelle  Femme Actuelle\n",
      "109  2020  Grand Prix Roman de l'été  Femme Actuelle  Femme Actuelle\n",
      "162  2021  Grand Prix Roman de l'été  Femme Actuelle  Femme Actuelle\n",
      "223  2022  Grand Prix Roman de l'été  Femme Actuelle  Femme Actuelle\n",
      "290  2023  Grand Prix Roman de l'été  Femme Actuelle  Femme Actuelle\n"
     ]
    }
   ],
   "source": [
    "df_femme_a = df_wikipedia[df_wikipedia['Titre']=='Femme Actuelle']\n",
    "print(df_femme_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correction manuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia.loc[df_wikipedia[\"Titre\"] == \"Femme Actuelle\", \"Prix\"] = \"Grand prix Roman de l'été de Femme Actuelle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia.loc[(df_wikipedia['Titre'] == 'Femme Actuelle') & (df_wikipedia['Année'] == 2019), ['Titre', 'Auteur']] = ['Au bout de la nuit', 'Bruno Bouzounie']\n",
    "df_wikipedia.loc[(df_wikipedia['Titre'] == 'Femme Actuelle') & (df_wikipedia['Année'] == 2020), ['Titre', 'Auteur']] = ['La Conjonction dorée', 'Benoît Sagaro']\n",
    "df_wikipedia.loc[(df_wikipedia['Titre'] == 'Femme Actuelle') & (df_wikipedia['Année'] == 2021), ['Titre', 'Auteur']] = ['Pour exister encore', 'Martine Duchesne']\n",
    "df_wikipedia.loc[(df_wikipedia['Titre'] == 'Femme Actuelle') & (df_wikipedia['Année'] == 2022), ['Titre', 'Auteur']] = [\"Le journal de Betty Swan\", 'Cindy Valt']\n",
    "df_wikipedia.loc[(df_wikipedia['Titre'] == 'Femme Actuelle') & (df_wikipedia['Année'] == 2023), ['Titre', 'Auteur']] = ['Hauteclaire', 'Dominique Delplace']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cas 5: Il y a aussi un problème avec les prix du journal le Monde, que nous avons corrigé manuellement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Année                      Prix               Auteur  Titre  prix_19_23\n",
      "42   2019  Prix littéraire du Monde  Une bête au paradis  Monde           1\n",
      "221  2022  Prix littéraire du Monde       Mathieu Belezi  Monde           1\n",
      "288  2023  Prix littéraire du Monde          Neige Sinno  Monde           1\n"
     ]
    }
   ],
   "source": [
    "df_monde = df_wikipedia[df_wikipedia['Titre']=='Monde']\n",
    "print(df_monde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia.loc[(df_wikipedia['Auteur'] == \"Une bête au paradis\") & (df_wikipedia['Titre'] == \"Monde\"),['Auteur','Titre']] = ['Cécile Coulon','Une bête au paradis']\n",
    "df_wikipedia.loc[(df_wikipedia['Auteur'] == \"Mathieu Belezi\") & (df_wikipedia['Titre'] == \"Monde\"),'Titre'] = ['Attaquer la terre et le soleil']\n",
    "df_wikipedia.loc[(df_wikipedia['Auteur'] == \"Neige Sinno\") & (df_wikipedia['Titre'] == \"Monde\"),'Titre'] = ['Triste tigre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous avons fait la remarque plus de l'ordre de la mise en page qu'il y a parfois dans les cases des précisions entre parenthèses ou crochets sur l'auteur ou le titre, précisions qui ne font pas partie du nom ni du titre de l'ouvrage. Ainsi, pour faciliter la future opération merge, nous avons décidé d'enlever ces choses de trop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia['Auteur'] = df_wikipedia['Auteur'].str.replace(r'\\(.*\\)', '', regex=True) #on enlève les parenthèses après les noms d'auteur\n",
    "df_wikipedia['Auteur'] = df_wikipedia['Auteur'].str.replace(r'\\[.*\\]', '', regex=True) # on enlève aussi les éventuels crochets\n",
    "df_wikipedia['Titre'] = df_wikipedia['Titre'].str.replace(r'\\[.*\\]', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a aussi des prix dont le nom nous a paru bizarre, mais étant donné que nous n'utilisons pas les noms des prix et construisons seulement une indicatrice indiquant si le livre a reçu un prix ou pas, nous n'en avons pas tenu compte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons commencé par compléter la base en scrappant Gallimard qui est un site fiable et bien codé. Le problème étant qu'il n'y a que les livres édités chez Gallimard sur ce site et donc qu'il faudra scrapper autre part pour compléter la base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "def search_gallimard(book_title, year):\n",
    "    #reformulation du titre en différente partie\n",
    "    parts = re.findall(r'\\w+|[^\\w\\s]', book_title)\n",
    "    book_title_gen = book_title.lower().strip()\n",
    "\n",
    "    # URL de recherche sur Livraddict\n",
    "    search_title = '+'.join(parts)\n",
    "    lower_search_title = '%20'.join(parts).lower()\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:118.0) Gecko/20100101 Firefox/118.0'}\n",
    "    search_url = f'https://www.gallimard.fr/catalogue?search_api_fulltext={search_title}&field_date_de_parution_1%5Bdate%5D={year}-01-01&field_date_de_parution_2%5Bdate%5D={year}-12-31&field_prix%5Bmin%5D=&field_prix%5Bmax%5D=&title_3=&items_per_page=20&sort_bef_combine=field_identifiant_catalogue_ASC'\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Faire une requête pour récupérer la page des résultats de recherche\n",
    "    response = requests.get(search_url, headers=headers).content\n",
    "    response_text = response.decode('utf-8')\n",
    "    # Trouver le premier élément correspondant au lien d'un résultat\n",
    "    page = soup(response_text, \"html.parser\")\n",
    "    results = page.find_all(\"div\", class_ = \"card--ouvrage\")\n",
    "    author = ''\n",
    "    for i in range(len(results)):\n",
    "        result = results[i]\n",
    "        div_title = result.find(\"div\", class_ = \"title\")\n",
    "        title = div_title.text\n",
    "        title_gen = title.lower().strip()\n",
    "        if book_title_gen == title_gen:\n",
    "            div_author = result.find('div', class_='paragraph paragraph--type--auteur paragraph--view-mode--links')\n",
    "            a_author = div_author.find(\"a\")\n",
    "            author = a_author.text\n",
    "    if author == '':\n",
    "        author = \"Pas trouvé sur Gallimard\"\n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_author(row):\n",
    "    if row[\"Auteur\"] == row[\"Titre\"] or re.match(r'^\\[\\d+\\]$', row['Auteur']) or row['Prix']=='Prix François-Mauriac' or row['Prix']=='Prix Maya':\n",
    "        author = search_gallimard(row[\"Titre\"], row[\"Année\"])\n",
    "        if author == None:\n",
    "            author = \"Problème dans la fonction?\"\n",
    "        return author\n",
    "    else:\n",
    "        return row[\"Auteur\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'opération prend entre 7 et 8 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia['Auteur'] = df_wikipedia.apply(search_author, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous l'avons indiqué plus haut, pour compléter ces données, nous avons scrapper sur le site de la Maison du Livre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_maison_du_livre(book_title, year):\n",
    "    #reformulation du titre en différente partie\n",
    "    parts = re.findall(r'\\w+|[^\\w\\s]', book_title)\n",
    "    book_title_gen = book_title.lower().strip()\n",
    "\n",
    "    # URL de recherche sur Livraddict\n",
    "    search_title = '+'.join(parts)\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:118.0) Gecko/20100101 Firefox/118.0'}\n",
    "    search_url = f'https://www.maisondulivre.com/listeliv.php?base=paper&mots_recherche={search_title}+{year}'\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Faire une requête pour récupérer la page des résultats de recherche\n",
    "    response = requests.get(search_url, headers=headers).content\n",
    "    response_text = response.decode('utf-8')\n",
    "\n",
    "    # Trouver le premier élément correspondant au lien d'un résultat\n",
    "    page = soup(response_text, \"html.parser\")\n",
    "    liste_livres = page.find('ul', {'id': 'liste_livres'})\n",
    "    livres = liste_livres.find_all(\"li\")\n",
    "    author = ''\n",
    "    for i in range(len(livres)):\n",
    "        livre = livres[i]\n",
    "        h2_titre = livre.find(\"h2\", class_=\"livre_titre\")\n",
    "        if h2_titre:\n",
    "            a_titre = h2_titre.find(\"a\")\n",
    "            titre = a_titre.get_text(strip=True)\n",
    "            title_adapted = re.sub(r'\\s?\\(.*?\\)', '', titre)\n",
    "            title_gen = title_adapted.lower().strip()\n",
    "            if title_gen == book_title_gen:\n",
    "                h2_auteur = livre.find(\"h2\", class_ = \"livre_auteur\")\n",
    "                if h2_auteur == None:\n",
    "                    auteur = \"Auteur non renseigné\"\n",
    "                else:\n",
    "                    a_auteur = h2_auteur.find(\"a\")\n",
    "                    author = a_auteur.get_text(strip=True)\n",
    "    if author == '':\n",
    "        author = \"Livre pas trouvé\"\n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_author(row):\n",
    "    if row[\"Auteur\"] == \"Pas trouvé sur Gallimard\":\n",
    "        author = search_maison_du_livre(row[\"Titre\"], row[\"Année\"])\n",
    "        if author == None:\n",
    "            author = \"Problème dans la fonction?\"\n",
    "        return author\n",
    "    else:\n",
    "        return row[\"Auteur\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'opération ci-dessous prend à peu près 7 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia['Auteur'] = df_wikipedia.apply(complete_author, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons la base de données pour vérifier qu'il n'y a plus d'incohérence et éventuellement les corriger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Année</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina</td>\n",
       "      <td>Sylvain Prudhomme</td>\n",
       "      <td>Par les routes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina étranger</td>\n",
       "      <td>Manuel Vilas</td>\n",
       "      <td>Ordesa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina essai</td>\n",
       "      <td>Emmanuelle Lambert</td>\n",
       "      <td>Giono furioso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Femina des lycéens</td>\n",
       "      <td>Victor Jestin</td>\n",
       "      <td>La Chaleur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Goncourt</td>\n",
       "      <td>Jean-Paul Dubois</td>\n",
       "      <td>Tous les hommes n'habitent pas le monde de la ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Goncourt du premier roman</td>\n",
       "      <td>Marie Gauthier</td>\n",
       "      <td>Court vêtue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Goncourt des lycéens</td>\n",
       "      <td>Karine Tuil</td>\n",
       "      <td>Les Choses humaines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Goncourt de la nouvelle</td>\n",
       "      <td>Caroline Lamarche</td>\n",
       "      <td>Nous sommes à la lisière</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019</td>\n",
       "      <td>Prix Goncourt de la biographie</td>\n",
       "      <td>Emily Dickinson</td>\n",
       "      <td>Manifeste incertain, volume 7 : Emily Dickinso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>Choix Goncourt de la Pologne</td>\n",
       "      <td>Louis-philippe Dalembert</td>\n",
       "      <td>Mur Méditerranée</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Année                            Prix                    Auteur  \\\n",
       "0  2019                     Prix Femina         Sylvain Prudhomme   \n",
       "1  2019            Prix Femina étranger              Manuel Vilas   \n",
       "2  2019               Prix Femina essai        Emmanuelle Lambert   \n",
       "3  2019         Prix Femina des lycéens             Victor Jestin   \n",
       "4  2019                   Prix Goncourt          Jean-Paul Dubois   \n",
       "5  2019  Prix Goncourt du premier roman            Marie Gauthier   \n",
       "6  2019       Prix Goncourt des lycéens               Karine Tuil   \n",
       "7  2019    Prix Goncourt de la nouvelle         Caroline Lamarche   \n",
       "8  2019  Prix Goncourt de la biographie           Emily Dickinson   \n",
       "9  2019    Choix Goncourt de la Pologne  Louis-philippe Dalembert   \n",
       "\n",
       "                                               Titre  \n",
       "0                                     Par les routes  \n",
       "1                                             Ordesa  \n",
       "2                                      Giono furioso  \n",
       "3                                         La Chaleur  \n",
       "4  Tous les hommes n'habitent pas le monde de la ...  \n",
       "5                                        Court vêtue  \n",
       "6                                Les Choses humaines  \n",
       "7                           Nous sommes à la lisière  \n",
       "8  Manifeste incertain, volume 7 : Emily Dickinso...  \n",
       "9                                   Mur Méditerranée  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wikipedia.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on le voit ci-dessous, il reste encore quelques livres qui n'ont pas été trouvés. Comme il n'y en a pas beaucoup, on corrige manuellement la base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Année                                  Prix            Auteur  \\\n",
      "14   2019                    Prix Médicis essai  Livre pas trouvé   \n",
      "17   2019       Prix Renaudot du livre de poche  Livre pas trouvé   \n",
      "24   2019                         Prix Décembre  Livre pas trouvé   \n",
      "48   2019                        Jacques Collin  Livre pas trouvé   \n",
      "61   2019                             Prix Maya  Livre pas trouvé   \n",
      "75   2020                          Prix Médicis  Livre pas trouvé   \n",
      "78   2020                         Prix Renaudot  Livre pas trouvé   \n",
      "88   2020                 Prix du premier roman  Livre pas trouvé   \n",
      "95   2020                         Prix de Flore  Livre pas trouvé   \n",
      "104  2020              Prix littéraire du Monde                     \n",
      "107  2020                           Tess Sharpe                     \n",
      "124  2020                             Prix Maya  Livre pas trouvé   \n",
      "150  2021                   Prix Première Plume                     \n",
      "152  2021                         Prix de Flore  Livre pas trouvé   \n",
      "155  2021                    Prix des libraires  Livre pas trouvé   \n",
      "157  2021  Prix Eugène-Dabit du roman populiste                     \n",
      "180  2022        Prix Goncourt de la biographie                     \n",
      "199  2022                 Prix François-Mauriac  Livre pas trouvé   \n",
      "209  2022                           Anne Berest                     \n",
      "210  2022      Prix littéraire ENS Paris-Saclay                     \n",
      "214  2022             Prix du Quai des Orfèvres                     \n",
      "217  2022  Prix Eugène-Dabit du roman populiste                     \n",
      "222  2022      Grand prix des lectrices de Elle                     \n",
      "225  2022       Grand Prix de Poésie de la SGDL                     \n",
      "227  2022                           Prix Wepler                     \n",
      "247  2023        Prix Goncourt de la biographie                     \n",
      "267  2023                 Prix François-Mauriac  Livre pas trouvé   \n",
      "292  2023                            Ada Palmer  Livre pas trouvé   \n",
      "297  2023   Prix littéraire de la Ville de Caen                     \n",
      "\n",
      "                                      Titre  \n",
      "14                              J'ai oublié  \n",
      "17   Une vieille histoire. Nouvelle version  \n",
      "24                         Les Grands Cerfs  \n",
      "48                                   Anatèm  \n",
      "61               Les Paupières des poissons  \n",
      "75                      Le Cœur synthétique  \n",
      "78                         Histoire du fils  \n",
      "88                            Adios Cow Boy  \n",
      "95                                 La Grâce  \n",
      "104                                   Monde  \n",
      "107                          Mon territoire  \n",
      "124                        Insolente Veggie  \n",
      "150          Avant que le monde ne se ferme  \n",
      "152                     Le Voyant d'Étampes  \n",
      "155                                Héritage  \n",
      "157                      Des gens comme eux  \n",
      "180                   Léopold Sédar Senghor  \n",
      "199                                    Zita  \n",
      "209                        La Carte postale  \n",
      "210                              Le Passeur  \n",
      "214                           La Muse rouge  \n",
      "217           Les Garçons de la cité-jardin  \n",
      "222                        La Carte postale  \n",
      "225                             Réacteur 3   \n",
      "227                    Les Enfants endormis  \n",
      "247                           Georges Perec  \n",
      "267       À l’abri des hommes et des choses  \n",
      "292                            Terra Ignota  \n",
      "297           Mourir avant que d'apparaître  \n"
     ]
    }
   ],
   "source": [
    "erreur_recherche = [\"Livre pas trouvé\", \"\"]\n",
    "df_verif =  df_wikipedia[df_wikipedia[\"Auteur\"].isin(erreur_recherche)]\n",
    "print(df_verif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrections manuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"J'ai oublié\", 'Auteur'] = 'Bulle Ogier'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"Une vieille histoire. Nouvelle version\", 'Auteur'] = 'Jonathan Littell'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"Les Grands Cerfs\", 'Auteur'] = 'Claudie Hunzinger'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"Anatèm\", 'Auteur'] = 'Neal Stephenson'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"Le Cœur synthétique\", 'Auteur'] = 'Chloé Delaume'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"Terra Ignota\", 'Auteur'] = 'Ada Palmer'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"Histoire du fils\", 'Auteur'] = 'Marie-Hélène Lafon'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"Adios Cow Boy\", 'Auteur'] = 'Olja Savičević Ivančević'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"La Grâce\", 'Auteur'] = 'Thibault de Montaigu'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"Le Voyant d'Étampes\", 'Auteur'] = 'Abel Quentin'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"Héritage\", 'Auteur'] = 'Miguel Bonnefoy'\n",
    "df_wikipedia.loc[(df_wikipedia['Titre'] == 'Les Paupières des poissons'), 'Auteur'] = 'Fanny Vaucher, Sébastien Moro'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == 'Insolente Veggie', 'Auteur'] = 'Rosa B.'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == 'Zita', 'Auteur'] = 'Olivier Hercend'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"À l’abri des hommes et des choses\", 'Auteur'] = 'Stéphanie Boulay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia.loc[(df_wikipedia['Prix'] == 'Prix littéraire du Monde') & (df_wikipedia['Année'] == 2020), ['Titre', 'Auteur']] = ['Elle a menti pour les ailes', 'Francesca Serra']\n",
    "df_wikipedia.loc[(df_wikipedia['Prix'] == 'Prix Eugène-Dabit du roman populiste') & (df_wikipedia['Année'] == 2021), 'Auteur'] =  'Samira Sedira'\n",
    "df_wikipedia.loc[(df_wikipedia['Titre'] == 'Mon territoire') & (df_wikipedia['Année'] == 2020), ['Prix', 'Auteur']] = ['Grand prix des lectrices (Elle)', 'Tess Sharpe']\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == 'Avant que le monde ne se ferme','Auteur'] = 'Alain Mascaro'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == 'Léopold Sédar Senghor','Auteur'] = ' Jean-Pierre Langellier'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == 'La Carte postale','Auteur'] = 'Anne Berest'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == 'Le Passeur','Auteur'] = 'Lois Lowry'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == 'La Muse rouge','Auteur'] = 'Véronique de Haas'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == 'Les Garçons de la cité-jardin','Auteur'] = 'Dan Nisand'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == 'Réacteur 3 ','Auteur'] = 'Ludovic Bernhardt'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == 'Les Enfants endormis','Auteur'] = 'Anthony Passeron'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == 'Georges Perec','Auteur'] = 'Claude Burgelin'\n",
    "df_wikipedia.loc[df_wikipedia['Titre'] == \"Mourir avant que d'apparaître\",'Auteur'] = 'Rémi David'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie qu'il n'y a plus de problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Année, Prix, Auteur, Titre, prix_19_23]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "erreur_recherche = [\"Livre pas trouvé\", \"\"]\n",
    "df_verif =  df_wikipedia[df_wikipedia[\"Auteur\"].isin(erreur_recherche)]\n",
    "print(df_verif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on rajoute une colonne de 1, indiquant que le livre a obtenu un prix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avant sauvegarde : Index(['Année', 'Prix', 'Auteur', 'Titre', 'prix_19_23'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# on ajoute une colonne indicatrice \"prix\" \n",
    "df_wikipedia['prix_19_23'] = 1\n",
    "print(\"Colonnes avant sauvegarde :\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Désormais, on essaye de simplifier la base afin de n'avoir plus de doublons de livre pour plus de simplicité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous avons décidé dans la nouvelle base de ne pas garder la colonne prix pour plus de simplicité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikifinal = df_wikipedia.drop(columns=['Prix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on s'attelle aux doublons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikifinal = df_wikifinal.drop_duplicates(subset=['Titre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions que cela a bien marché."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Année, Auteur, Titre, prix_19_23, Doublons]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_wikifinal['Doublons'] = df_wikifinal['Titre'].duplicated(keep=False)  # Repère tous les doublons\n",
    "\n",
    "# Afficher uniquement les lignes dupliquées\n",
    "doublons = df_wikifinal[df_wikifinal['Doublons']]\n",
    "print(doublons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rendre la base propre, on enlève la colonne \"Doublons\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikifinal = df_wikifinal.drop(columns=['Doublons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on peut modifier le fichier CSV avec les modifications afin de le fusionner plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikifinal.to_csv(\"prix_litteraires.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie 3: import des données Youtube. On ne mergera pas la base Youtube avec les autres. Le but sera de compter le nombre d'occurence de chacun livre de la première base dans cette dernière. On a obtenu ces données à partir de l'API disponibles en ligne. Toutefois, la base comportant des données sensibles, nous ne mettrons pas la clé accessible dans le Github, nous la partagerons nous même avec les personnes intéressées par nos données. On se limites aux vidéos sorties entre 2019 et 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Remplacez key par sa propre clé API\n",
    "\n",
    "# Fonction pour récupérer les vidéos avec des dates spécifiques\n",
    "def get_videos(query, start_date=\"2019-01-01T00:00:00Z\", end_date=\"2023-12-31T23:59:59Z\", max_results=50,key):\n",
    "    url = f'https://www.googleapis.com/youtube/v3/search?part=snippet&q={query}&type=video&maxResults={max_results}&publishedAfter={start_date}&publishedBefore={end_date}&key={key}'\n",
    "    response = requests.get(url)  # Requête pour rechercher des vidéos\n",
    "    data = response.json()\n",
    "\n",
    "    videos = []\n",
    "    for video in data['items']:\n",
    "        video_info = {\n",
    "            'video_id': video['id']['videoId'],\n",
    "            'title': video['snippet']['title'],\n",
    "            'description': video['snippet']['description'],\n",
    "            'published_at': video['snippet']['publishedAt'],\n",
    "            'channel_title': video['snippet']['channelTitle']\n",
    "        }\t\n",
    "        videos.append(video_info)\n",
    "\n",
    "    # Récupérer les pages suivantes si nécessaire\n",
    "    next_page_token = data.get('nextPageToken')\n",
    "    while next_page_token:\n",
    "        url = f'https://www.googleapis.com/youtube/v3/search?part=snippet&q={query}&type=video&maxResults={max_results}&pageToken={next_page_token}&publishedAfter={start_date}&publishedBefore={end_date}&key={key}'\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        for video in data['items']:\n",
    "            video_info = {\n",
    "                'video_id': video['id']['videoId'],\n",
    "                'title': video['snippet']['title'],\n",
    "                'description': video['snippet']['description'],\n",
    "                'published_at': video['snippet']['publishedAt'],\n",
    "                'channel_title': video['snippet']['channelTitle']\n",
    "            }\n",
    "            videos.append(video_info)\n",
    "        next_page_token = data.get('nextPageToken')\n",
    "\n",
    "    return videos\n",
    "\n",
    "# Appel de la fonction pour récupérer les vidéos entre 2019 et 2023\n",
    "query = \"livre\"\n",
    "videos = get_videos(query, start_date=\"2019-01-01T00:00:00Z\", end_date=\"2023-12-31T23:59:59Z\", max_results=50, key)\n",
    "\n",
    "# Convertir les données en DataFrame\n",
    "df = pd.DataFrame(videos)\n",
    "\n",
    "# Sauvegarder le DataFrame sous forme de fichier CSV\n",
    "df.to_csv('youtube_livre_2019_2023.csv', index=False)\n",
    "\n",
    "print(\"Le fichier CSV a été créé avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie 4: on merge les différentes bases pour simplifier l'analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par charger les dataframe à partir des CSV. Cette étape nous permet à l'échelle d'une journée de pouvoir ne pas recharger toutes les bases à chaque fois. Toutefois, nous n'effectuons pas forcément cette ligne de code à chaque fois. Si nous venons de refaire tourner tout le code, on peut skipper cette partie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_books_fnac_2023 = pd.read_csv(\"best_sellers_fnac_2023_cleaned.csv\")\n",
    "df_babelio_data = pd.read_csv(\"23 livres les plus lus Babelio.csv\")\n",
    "df_livraddict_data = pd.read_csv(\"livraddict_prix_2024.csv\")\n",
    "df_wikifinal = pd.read_csv(\"prix_litteraires.csv\")\n",
    "df_bibli = pd.read_csv(\"Les livres les plus empruntés à Paris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est nécessaire de renommer certaines colonnes pour standardiser le tout. Pour le moment, nous gardons les variables type_de_document et Catégorie respectivement des bases de bibliothèque et de Livraddict. Peut-être pourra-t-on s'intéresser très rapidement dans nos statistiques descriptives aux notes des ouvrages selon le genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bibli = df_bibli.rename(columns={'titre': 'Titre'})\n",
    "df_bibli_formerge = df_bibli.rename(columns={'reservations': 'Nb réservations bibli'})\n",
    "df_bibli_formerge = df_bibli_formerge.rename(columns={'auteur': 'Auteur'})\n",
    "df_bibli_formerge = df_bibli_formerge.drop(columns=['rang', 'Nb réservations bibli', 'Classement bibliothèque'])\n",
    "df_wikifinal = df_wikifinal.drop(columns=['Année'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on normalise les titres en mettant tout en majuscule et en enlevant les espaces qui peuvent se créer avant le début ou après la fin de la chaîne de caractères. Le but est qu'il n'y ait pas d'erreur au moment du merge, ou le moins possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_books_fnac_2023['Titre'] = df_top_books_fnac_2023['Titre'].str.lower().str.strip()\n",
    "df_babelio_data['Titre'] = df_babelio_data['Titre'].str.lower().str.strip()\n",
    "df_livraddict_data['Titre'] = df_livraddict_data['Titre'].str.lower().str.strip()\n",
    "df_wikifinal['Titre'] = df_wikifinal['Titre'].str.lower().str.strip()\n",
    "df_bibli_formerge['Titre'] = df_bibli['Titre'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, on fait notre opération merge. On merge les bases mes unes avec les autre l'une après l'autre.\n",
    "On doit également retravailler à chaque fois la colonne \"Auteur\". L'idée c'est de créer une colonne unique \"Auteur\" pour réunir toutes les information d'auteur dans une seule variable on donne un ordre de priorité: Auteur, Auteur_x, Auteur_y\n",
    "si une colonne contient une valeur manquante (NaN), elle est remplit par la valeur de la colonne suivante.\n",
    "La méthode .combine_first() remplit les valeurs manquantes (NaN) de la colonne de gauche (merged_df['Auteur']) \n",
    "avec les valeurs correspondantes de la colonne de droite (merged_df['Auteur_x'])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_top_books_fnac_2023.merge(df_babelio_data, on=\"Titre\", how=\"outer\")\n",
    "merged_df['Auteur']= None\n",
    "merged_df['Auteur'] = merged_df['Auteur'].combine_first(merged_df['Auteur_x']).combine_first(merged_df['Auteur_y'])\n",
    "merged_df.drop(columns=['Auteur_x', 'Auteur_y'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(df_livraddict_data, on=\"Titre\", how=\"outer\")\n",
    "merged_df['Auteur']= None\n",
    "merged_df['Auteur'] = merged_df['Auteur'].combine_first(merged_df['Auteur_x']).combine_first(merged_df['Auteur_y'])\n",
    "merged_df.drop(columns=['Auteur_x', 'Auteur_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(df_wikifinal, on=\"Titre\", how=\"outer\")\n",
    "merged_df['Auteur']= None\n",
    "merged_df['Auteur'] = merged_df['Auteur'].combine_first(merged_df['Auteur_x']).combine_first(merged_df['Auteur_y'])\n",
    "merged_df.drop(columns=['Auteur_x', 'Auteur_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(df_bibli_formerge, on=\"Titre\", how=\"outer\")\n",
    "merged_df['Auteur']= None\n",
    "merged_df['Auteur'] = merged_df['Auteur'].combine_first(merged_df['Auteur_x']).combine_first(merged_df['Auteur_y'])\n",
    "merged_df.drop(columns=['Auteur_x', 'Auteur_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>top_fnac_1</th>\n",
       "      <th>top_fnac_2_plus</th>\n",
       "      <th>top_babelio</th>\n",
       "      <th>Catégorie</th>\n",
       "      <th>top_livraddict</th>\n",
       "      <th>prix_19_23</th>\n",
       "      <th>type_de_document</th>\n",
       "      <th>Top bibliothèque</th>\n",
       "      <th>Auteur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(très) cher cinéma français</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Éric Neuhoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hélène Gestern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adieu birkenau</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ginette Kolinka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adieu tanger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salma El Moumni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adios cow boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Olja Savičević Ivančević</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anatèm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neal Stephenson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apeirogon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colum McCann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arcadie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emmanuelle Bayamack-Tam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>argonne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stéphane Emond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>astérix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hors collection : L’Empire du milieu – Fabrice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>astérix tome 40 : l’iris blanc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Didier Conrad, Fabcaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>astérix, hors collection : l’empire du milieu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fabrice Tarrin, Olivier Gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>astérix, tome 40 : l’iris blanc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Didier Conrad, Fabcaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>attaque au clair de lune</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bande dessinée jeunesse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Oda,  Eiichiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>attaquer la terre et le soleil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mathieu Belezi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Titre  top_fnac_1  \\\n",
       "0                     (très) cher cinéma français         NaN   \n",
       "1                                             555         NaN   \n",
       "2                                  adieu birkenau         1.0   \n",
       "3                                    adieu tanger         NaN   \n",
       "4                                   adios cow boy         NaN   \n",
       "5                                          anatèm         NaN   \n",
       "6                                       apeirogon         NaN   \n",
       "7                                         arcadie         NaN   \n",
       "8                                         argonne         NaN   \n",
       "9                                         astérix         1.0   \n",
       "10                 astérix tome 40 : l’iris blanc         1.0   \n",
       "11  astérix, hors collection : l’empire du milieu         1.0   \n",
       "12                astérix, tome 40 : l’iris blanc         1.0   \n",
       "13                       attaque au clair de lune         NaN   \n",
       "14                 attaquer la terre et le soleil         NaN   \n",
       "\n",
       "    top_fnac_2_plus  top_babelio Catégorie  top_livraddict  prix_19_23  \\\n",
       "0               NaN          NaN       NaN             NaN         1.0   \n",
       "1               NaN          NaN       NaN             NaN         1.0   \n",
       "2               0.0          NaN        Bd             1.0         NaN   \n",
       "3               NaN          NaN       NaN             NaN         1.0   \n",
       "4               NaN          NaN       NaN             NaN         1.0   \n",
       "5               NaN          NaN       NaN             NaN         1.0   \n",
       "6               NaN          NaN       NaN             NaN         1.0   \n",
       "7               NaN          NaN       NaN             NaN         1.0   \n",
       "8               NaN          NaN       NaN             NaN         1.0   \n",
       "9               0.0          NaN       NaN             NaN         NaN   \n",
       "10              0.0          NaN       NaN             NaN         NaN   \n",
       "11              0.0          NaN       NaN             NaN         NaN   \n",
       "12              1.0          NaN       NaN             NaN         NaN   \n",
       "13              NaN          NaN       NaN             NaN         NaN   \n",
       "14              NaN          NaN       NaN             NaN         1.0   \n",
       "\n",
       "           type_de_document  Top bibliothèque  \\\n",
       "0                       NaN               NaN   \n",
       "1                       NaN               NaN   \n",
       "2                       NaN               NaN   \n",
       "3                       NaN               NaN   \n",
       "4                       NaN               NaN   \n",
       "5                       NaN               NaN   \n",
       "6                       NaN               NaN   \n",
       "7                       NaN               NaN   \n",
       "8                       NaN               NaN   \n",
       "9                       NaN               NaN   \n",
       "10                      NaN               NaN   \n",
       "11                      NaN               NaN   \n",
       "12                      NaN               NaN   \n",
       "13  Bande dessinée jeunesse               1.0   \n",
       "14                      NaN               NaN   \n",
       "\n",
       "                                               Auteur  \n",
       "0                                        Éric Neuhoff  \n",
       "1                                      Hélène Gestern  \n",
       "2                                     Ginette Kolinka  \n",
       "3                                     Salma El Moumni  \n",
       "4                            Olja Savičević Ivančević  \n",
       "5                                     Neal Stephenson  \n",
       "6                                        Colum McCann  \n",
       "7                             Emmanuelle Bayamack-Tam  \n",
       "8                                     Stéphane Emond   \n",
       "9   Hors collection : L’Empire du milieu – Fabrice...  \n",
       "10                             Didier Conrad, Fabcaro  \n",
       "11                        Fabrice Tarrin, Olivier Gay  \n",
       "12                             Didier Conrad, Fabcaro  \n",
       "13                                     Oda,  Eiichiro  \n",
       "14                                     Mathieu Belezi  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Désormais, on remplace toutes les valeurs None par des 0 afin d'avoir une base propre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place0(row):\n",
    "    global column\n",
    "    if np.isnan(row[column]):\n",
    "        value = 0\n",
    "    else:\n",
    "        value = row[column]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['top_fnac_1', 'top_fnac_2_plus', 'top_babelio', 'top_livraddict', 'prix_19_23', 'Top bibliothèque']\n",
    "for i in range(0,len(columns)):\n",
    "    column = columns[i]\n",
    "    merged_df[column] = merged_df.apply(place0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>top_fnac_1</th>\n",
       "      <th>top_fnac_2_plus</th>\n",
       "      <th>top_babelio</th>\n",
       "      <th>Catégorie</th>\n",
       "      <th>top_livraddict</th>\n",
       "      <th>prix_19_23</th>\n",
       "      <th>type_de_document</th>\n",
       "      <th>Top bibliothèque</th>\n",
       "      <th>Auteur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(très) cher cinéma français</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Éric Neuhoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hélène Gestern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adieu birkenau</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ginette Kolinka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adieu tanger</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Salma El Moumni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adios cow boy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Olja Savičević Ivančević</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anatèm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neal Stephenson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apeirogon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Colum McCann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arcadie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Emmanuelle Bayamack-Tam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Titre  top_fnac_1  top_fnac_2_plus  top_babelio  \\\n",
       "0  (très) cher cinéma français         0.0              0.0          0.0   \n",
       "1                          555         0.0              0.0          0.0   \n",
       "2               adieu birkenau         1.0              0.0          0.0   \n",
       "3                 adieu tanger         0.0              0.0          0.0   \n",
       "4                adios cow boy         0.0              0.0          0.0   \n",
       "5                       anatèm         0.0              0.0          0.0   \n",
       "6                    apeirogon         0.0              0.0          0.0   \n",
       "7                      arcadie         0.0              0.0          0.0   \n",
       "\n",
       "  Catégorie  top_livraddict  prix_19_23 type_de_document  Top bibliothèque  \\\n",
       "0       NaN             0.0         1.0              NaN               0.0   \n",
       "1       NaN             0.0         1.0              NaN               0.0   \n",
       "2        Bd             1.0         0.0              NaN               0.0   \n",
       "3       NaN             0.0         1.0              NaN               0.0   \n",
       "4       NaN             0.0         1.0              NaN               0.0   \n",
       "5       NaN             0.0         1.0              NaN               0.0   \n",
       "6       NaN             0.0         1.0              NaN               0.0   \n",
       "7       NaN             0.0         1.0              NaN               0.0   \n",
       "\n",
       "                     Auteur  \n",
       "0              Éric Neuhoff  \n",
       "1            Hélène Gestern  \n",
       "2           Ginette Kolinka  \n",
       "3           Salma El Moumni  \n",
       "4  Olja Savičević Ivančević  \n",
       "5           Neal Stephenson  \n",
       "6              Colum McCann  \n",
       "7   Emmanuelle Bayamack-Tam  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
